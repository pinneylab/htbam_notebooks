{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing Template\n",
    "___\n",
    "### Version 0.2.1\n",
    "Duncan Muir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from htbam_analysis.processing import chip\n",
    "from htbam_analysis.processing import experiment as exp\n",
    "from htbam_analysis.processing import chipcollections as collections\n",
    "from pathlib import Path \n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Establish experiment and pinlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     Experiment Initialized | Description: standard_curve_debugging, Operator: DFM\n"
     ]
    }
   ],
   "source": [
    "root = '/path/to/experiment/directory/'\n",
    "description = 'something_descriptive'\n",
    "operator = 'whoami'\n",
    "setup_num = 's#'\n",
    "device_num = 'd#'\n",
    "device_dimensions = (32, 56)\n",
    "e = exp.Experiment(description, root, operator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Exposure and Channel Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_quant_channel = 'egfp'\n",
    "button_quant_exposure = 500\n",
    "standard_channel = \"PBP\"\n",
    "standard_exposure = 100\n",
    "kinetics_channel = 'fura'\n",
    "kinetics_exposure = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mock a Pinlist for Flow-On Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a fake pinlist\n",
    "#block 1 is the left side of the image, but right side of the device\n",
    "block_descriptions = {1: 'protein_1', 2: 'protein_1', 3: 'protein_2', 4: 'protein_2'}\n",
    "def get_block(c):\n",
    "    return ((c // 8) + 1)\n",
    "#creating a pin list\n",
    "pinlist_dict = []\n",
    "for c in range(32):\n",
    "    for r in range(56):\n",
    "        block = get_block(c)\n",
    "        mutant = block_descriptions[block]\n",
    "        pinlist_dict.append({'Indices': (c + 1, r + 1), 'MutantID': mutant})\n",
    "pinlist_df = pd.DataFrame(pinlist_dict)\n",
    "pinlist_path = f'{root}/data_analysis/20230208_pinlist.csv'\n",
    "pinlist_df.to_csv(pinlist_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Indices</th>\n",
       "      <th>MutantID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>Mac1_WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>Mac1_WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>Mac1_WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>Mac1_WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1, 5)</td>\n",
       "      <td>Mac1_WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Indices MutantID\n",
       "x y                 \n",
       "1 1  (1, 1)  Mac1_WT\n",
       "  2  (1, 2)  Mac1_WT\n",
       "  3  (1, 3)  Mac1_WT\n",
       "  4  (1, 4)  Mac1_WT\n",
       "  5  (1, 5)  Mac1_WT"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinlist = e.read_pinlist(f'{root}/data_analysis/20230208_pinlist.csv')\n",
    "pinlist.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add devices and corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top left, top right, bottom left, bottom right\n",
    "d3_corners = ((452, 450),(6723,441),(472,6817),(6742,6800)) \n",
    "\n",
    "#Do this in imageJ, put your cursor over the reaction chambers and copy over\n",
    "d3 = exp.Device(setup_num, device_num, device_dimensions, pinlist, d3_corners)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-standard chamber-finding parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Chamber Radius: 32 pixels\n",
      "New Chamber Radius: 32 pixels\n"
     ]
    }
   ],
   "source": [
    "#chip.Stamp.circlePara1Index = 30\n",
    "#chip.Stamp.circlePara2Index = 15\n",
    "\n",
    "print('Old Chamber Radius: {} pixels'.format(chip.Stamp.chamberrad))\n",
    "chip.Stamp.chamberrad = 32#33 in 2x2\n",
    "print('New Chamber Radius: {} pixels'.format(chip.Stamp.chamberrad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Execute button analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantify egfp fluorescence on buttons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stitched image path\n",
    "button_quant_path = f'{root}/button_quant/20230401-095714-d2_egfp-quant_pre-MM_egfp_500_Sola_2x2_Kinetix-DynamicRange_4x/egfp/StitchedImages/BGSubtracted_StitchedImg_500_egfp_0.tif'\n",
    "\n",
    "# Prepare ChipQuant object\n",
    "d3_GFPQuant = collections.ChipQuant(d3, 'ButtonReference')\n",
    "\n",
    "# Load image into memory\n",
    "d3_GFPQuant.load_file(button_quant_path, button_quant_channel, button_quant_exposure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Buttons: 100%|██████████| 1792/1792 [03:04<00:00,  9.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# Find buttons, extract intensity attributes\n",
    "d3_GFPQuant.process()\n",
    "\n",
    "# Summarize attributes as a pandas dataframe\n",
    "quant_report1 = d3_GFPQuant.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Summary/Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_report1.to_csv(f'{root}/desired/file/name')\n",
    "\n",
    "d3_GFPQuant.save_summary_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define standard corners (if these are the same as your device above, you don't need to)\n",
    "# Top left, top right, bottom left, bottom right\n",
    "# new_corners = ((452, 450),(6723,441),(472,6817),(6742,6800))\n",
    "d3_std_dev = exp.Device(setup_num, device_num, device_dimensions, pinlist, d3_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a standard series, load stitched images\n",
    "standard_path = '/Volumes/T7/20221208_Mat2a_analysis.v2/20221202_tracy/standard_curve/Analysis_resized/dapi/StitchedImages'\n",
    "\n",
    "d3_std = collections.StandardSeries(d3_std_dev, standard_channel)\n",
    "d3_std.load_files(standard_path, standard_channel, standard_exposure)\n",
    "d3_std.process(featuretype=\"chamber\", coerce_center=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3_std.save_summary()\n",
    "d3_std.save_summary_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Chamber Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code is having a hard time finding chambers in the standard curve (perhaps because it was resized?), so using this image as a reference\n",
    "\n",
    "d3_ChamberRef = collections.ChipQuant(d3, 'Chamber_Ref')\n",
    "chamber_ref = '/Users/duncanmuir/Desktop/20231114_std_curve_test_data_duncan/standard/Analysis/StitchedImg_1000_5_500.tif'\n",
    "d3_ChamberRef.load_file(chamber_ref, 'fura', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d3_ChamberRef.process(mapped_features = 'chamber', coerce_center = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3_ChamberRef.save_summary_image(feature_type = 'chamber')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Kinetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assay Series Descriptions & Object\n",
    "parent = Path('/Volumes/DuncanSSD/20230331/kinetics/')\n",
    "\n",
    "kinetic_descriptions = ['7_8125uM_ADP',\n",
    "                        # '15_6125uM_ADP',\n",
    "                        # '31_25uM_ADP',\n",
    "                        # '62_5uM_ADP',\n",
    "                        # '125uM_ADP',\n",
    "                        # '250uM_ADP',\n",
    "                        # '500uM_ADP',\n",
    "                        # '1000uM_ADP',\n",
    "                        ]\n",
    "\n",
    "# References (for positions)\n",
    "chamberRef = d3_ChamberRef.chip\n",
    "buttonRef = d3_GFPQuant.chip\n",
    "\n",
    "# the name of your button quant files\n",
    "gfp_descriptions = ['egfp-quant_pre-MM']\n",
    "\n",
    "kinetic_file_handles = kinetic_descriptions\n",
    "gfp_file_handles = gfp_descriptions\n",
    "\n",
    "adk_orth = collections.AssaySeries(d3, \n",
    "                                kinetic_descriptions, \n",
    "                                chamberRef, \n",
    "                                buttonRef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kin_root = '/Volumes/DuncanSSD/20230331/kinetics/'\n",
    "\n",
    "adk_orth.parse_kineticsFolders(kin_root, kinetic_file_handles, kinetic_descriptions, kinetics_channel, kinetics_exposure)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_root = '/Volumes/DuncanSSD/20230331/button_quant/'\n",
    "\n",
    "adk_orth.parse_quantificationFolders(button_root, gfp_descriptions, gfp_file_handles, button_quant_channel, button_quant_exposure)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Series <7_8125uM-ADP> Stamped and Mapped: 100%|██████████| 20/20 [00:39<00:00,  1.96s/it]\n"
     ]
    }
   ],
   "source": [
    "adk_orth.process_kinetics(low_mem = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping and Processing Buttons: 100%|██████████| 12/12 [00:50<00:00,  4.20s/it]\n"
     ]
    }
   ],
   "source": [
    "adk_orth.process_quants()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "adk_orth.save_summary(outPath = kin_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Binding Assay\n",
    "\n",
    "There are three images taken for each concentration of prey: \n",
    "1. A pre-wash measurement of the bait.\n",
    "2. A post-wash measurement of the bait.\n",
    "3. A post-wash measurement of the prey.\n",
    "\n",
    "I process these images by first re-formatting the directory outputteed by the binding experiment into a format identical to that of a kinetics experiment. I've included some code for doing this in the cell below. Keep in mind this may require some tweaks depending on how your files or directories are named. For instance, the `get_handle()` and `concen_from_handle()` functions used to extract experiment data from filenames will almost certainly need to be tailored for your specific experiment.\n",
    "\n",
    "This is a hacky solution that will probably work alright until a newer version of the processing code is published. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-format the Binding Experiment Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create necessary directories, copy files, and rename files programatically\n",
    "\n",
    "import os \n",
    "import shutil \n",
    "import numpy as np\n",
    "\n",
    "binding_path = 'path/to/binding/experiment/dir'\n",
    "bait_channel, bait_exposure = '3', '10'\n",
    "prey_channel, prey_exposure = '2', '10'\n",
    "\n",
    "pre_wash_bait_dir = os.path.join(binding_path, 'pre_wash_bait')\n",
    "post_wash_bait_dir = os.path.join(binding_path, 'post_wash_bait')\n",
    "post_wash_prey_dir = os.path.join(binding_path, 'post_wash_prey')\n",
    "\n",
    "def get_handle(filename: str):\n",
    "\n",
    "    substring = filename.split('-')[-1]\n",
    "    substring = substring.split('_P')[0]\n",
    "    substring = substring.split('d1')[-1]\n",
    "    \n",
    "    return substring[1:]\n",
    "\n",
    "def concen_from_handle(handle: str, prey_name: str):\n",
    "\n",
    "    concen_string = handle.split(prey_name)[0][0:-1]\n",
    "    concen_string = concen_string.replace('_', '.')\n",
    "\n",
    "    return float(concen_string)\n",
    "\n",
    "source_dirs = os.listdir(binding_path)\n",
    "source_dirs.sort()\n",
    "source_dirs = source_dirs[0:-1]\n",
    "file_handles = [get_handle(dir) for dir in source_dirs]\n",
    "concens = [concen_from_handle(handle, 'GEF') for handle in file_handles]\n",
    "\n",
    "target_dirs = np.array([''] * len(file_handles), dtype='<U80')\n",
    "target_dirs[0::3] = pre_wash_bait_dir\n",
    "target_dirs[1::3] = post_wash_bait_dir\n",
    "target_dirs[2::3] = post_wash_prey_dir\n",
    "\n",
    "exposures = np.array([''] * len(file_handles), dtype='<U3')\n",
    "exposures[0::3] = bait_exposure\n",
    "exposures[1::3] = bait_exposure\n",
    "exposures[2::3] = prey_exposure\n",
    "\n",
    "channels = np.array([''] * len(file_handles), dtype='<U3')\n",
    "channels[0::3] = bait_channel\n",
    "channels[1::3] = bait_channel\n",
    "channels[2::3] = prey_channel\n",
    "\n",
    "def add_nested_folders(target_dirs: np.ndarray, channels: np.ndarray):\n",
    "    \n",
    "    nested_folders = []\n",
    "    for dir, channel in zip(target_dirs[0:3], channels[0:3]):\n",
    "\n",
    "        channel_subdir = os.path.join(dir, channel)\n",
    "        images_subdir = os.path.join(channel_subdir, 'StitchedImages')\n",
    "        nested_folders.append(images_subdir)\n",
    "\n",
    "        if not os.path.exists(dir):\n",
    "            os.mkdir(dir)\n",
    "            os.mkdir(channel_subdir)\n",
    "            os.mkdir(images_subdir)\n",
    "\n",
    "        else:\n",
    "            print(f'ERROR: {dir} already exists!')\n",
    "\n",
    "    return nested_folders\n",
    "\n",
    "target_dirs = add_nested_folders(target_dirs, channels)\n",
    "for index in range(len(file_handles)):\n",
    "\n",
    "    source_dir = source_dirs[index]\n",
    "    handle = file_handles[index]\n",
    "    concen = concens.index(concens[index])\n",
    "    target_dir = target_dirs[index]\n",
    "    exposure = exposures[index]\n",
    "    channel = channels[index]\n",
    "\n",
    "    target_filename = 'BGSubtracted_StitchedImg_{}_{}_{}.tif'\n",
    "    target_filename = target_filename.format(\n",
    "        exposure,\n",
    "        channel,\n",
    "        concen\n",
    "    )\n",
    "    target_filename = os.path.join(binding_path, target_dir, target_filename)\n",
    "\n",
    "    source_filename = os.path.join(\n",
    "        binding_path, \n",
    "        source_dir, \n",
    "        channel, \n",
    "        'StitchedImages',\n",
    "        'StitchedImg_{}_{}_{}.tif'.format(exposure, channel, 0)\n",
    "        )\n",
    "\n",
    "    shutil.copyfile(source_filename, target_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Establish Button Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_ref_image = 'path/to/button/ref/image.tif'\n",
    "button_ref_channel, button_ref_exposure = '2', 10\n",
    "\n",
    "button_ref = collections.ChipQuant(d3, 'button_ref')\n",
    "button_ref.load_file(button_ref_image, button_ref_channel, button_ref_exposure)\n",
    "button_ref.process(mapped_features = 'button')\n",
    "button_ref.save_summary_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Bait and Prey Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process each image type as if it were a collection of kinetic images\n",
    "binding_path = 'path/to/Analysis'\n",
    "bait_channel, bait_exposure = '3', '10'\n",
    "prey_channel, prey_exposure = '2', '10'\n",
    "\n",
    "# first, process the bait\n",
    "bait_handles = ['pre_wash_bait', 'post_wash_bait']\n",
    "binding_bait = collections.ButtonChamberAssaySeries(\n",
    "    device=d3,\n",
    "    descriptions=bait_handles,\n",
    "    chamber_ref=d3_ChamberRef.chip,\n",
    "    button_ref=button_ref.chip,\n",
    "    channels=[bait_channel]\n",
    ")\n",
    "binding_bait.parse_kineticsFolders(\n",
    "    root=binding_path,\n",
    "    file_handles=bait_handles,\n",
    "    descriptors=bait_handles,\n",
    "    channel=bait_channel,\n",
    "    exposure=bait_exposure)\n",
    "binding_bait.process_kinetics(featuretype='button', low_mem=False)\n",
    "binding_bait.save_summary()\n",
    "\n",
    "# then, process the prey \n",
    "prey_handles = ['post_wash_prey']\n",
    "binding_prey = collections.ButtonChamberAssaySeries(\n",
    "    device=d3,\n",
    "    descriptions=prey_handles,\n",
    "    chamber_ref=d3_ChamberRef.chip,\n",
    "    button_ref=button_ref.chip,\n",
    "    channels=[prey_channel]\n",
    ")\n",
    "binding_prey.parse_kineticsFolders(\n",
    "    root=binding_path,\n",
    "    file_handles=prey_handles,\n",
    "    descriptors=prey_handles,\n",
    "    channel=prey_channel,\n",
    "    exposure=prey_exposure\n",
    ")\n",
    "binding_prey.process_kinetics(featuretype='button', low_mem=False)\n",
    "binding_prey.save_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('htbam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9d5eb981a451804117bbb533ea06cb0ae54737992d6851237fb03142364cb8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
