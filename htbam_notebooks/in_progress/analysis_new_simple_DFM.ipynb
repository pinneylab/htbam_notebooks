{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Template\n",
    "An even newer version... I am trying to simplify our initial rate fitting and make it easier to QC the results.\n",
    "DFM 4/30/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS:\n",
    "EGFP_SLOPE = 91900.03\n",
    "EGFP_SLOPE_CONC_UNITS = 'nM' #RFU/nM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enables autoreloding of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import skimage\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.optimize import curve_fit\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dash import Dash, dcc, html, Input, Output, no_update\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "from pathlib import Path \n",
    "from htbam_db_api.htbam_db_api import LocalHtbamDBAPI\n",
    "\n",
    "#Import Kinetics Package for line fitting:\n",
    "import kinetics\n",
    "\n",
    "#Configuration settings for pandas and seaborn\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "sns.set(style='ticks', context='paper', font_scale=1.2, rc={\"lines.linewidth\": 1.2})\n",
    "\n",
    "#enable inline plotting of matplotlib figures\n",
    "%matplotlib inline\n",
    "\n",
    "#set the figure format to SVG\n",
    "%config InlineBackend.figure_format = 'svg'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Helper Functions\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert from DB to numpy arrays quickly:\n",
    "\n",
    "def assay_data_to_array(db_obj, run_name):\n",
    "    '''This function takes as input an HTBAM Database object.\n",
    "    For each kinetics run, we have \n",
    "    It returns 3 numpy arrays:\n",
    "    chamber_ids: an array of the chamber ids (in the format '1,1' ... '32,56')\n",
    "        shape: (n_chambers,)\n",
    "    luminance_data: an array of the luminance data for each chamber\n",
    "        shape: (n_time_points, n_chambers, n_assays)\n",
    "    conc_data: an array of the concentration data for each chamber.\n",
    "        shape: (n_assays,)\n",
    "    time_data: an array of the time data for each time point.\n",
    "        shape: (n_time_points, n_assays)\n",
    "    '''\n",
    "    \n",
    "    chamber_idxs = np.array(list(db_obj._json_dict['chamber_metadata'].keys()))\n",
    "    luminance_data = None\n",
    "    time_data = None\n",
    "    conc_data = np.array([])\n",
    "\n",
    "    #Each assay may have recorded a different # of time points.\n",
    "    #First, we'll just check what the max # of time points is:\n",
    "    max_time_points = 0\n",
    "    for assay in db_obj._json_dict[\"runs\"][run_name]['assays'].keys():\n",
    "        current_assay_time_points = len(np.array(db_obj._json_dict[\"runs\"][run_name]['assays'][assay]['time_s']))\n",
    "        if current_assay_time_points > max_time_points:\n",
    "            max_time_points = current_assay_time_points\n",
    "\n",
    "    for assay in db_obj._json_dict[\"runs\"][run_name]['assays'].keys():\n",
    "        \n",
    "        #to make things easier later, we'll be sorting the datapoints by time value.\n",
    "        #Get time data:\n",
    "        #collect from DB\n",
    "        current_time_array = np.array(db_obj._json_dict[\"runs\"][run_name]['assays'][assay]['time_s'])\n",
    "        current_time_array = current_time_array.astype(float) #so we can pad with NaNs\n",
    "        #pad the array with NaNs if there are fewer time points than the max\n",
    "        current_time_array = np.pad(current_time_array, (0, max_time_points - len(current_time_array)), 'constant', constant_values=np.nan)\n",
    "        #sort, and capture sorting idxs:\n",
    "        sorting_idxs = np.argsort(current_time_array)\n",
    "        current_time_array = current_time_array[sorting_idxs]\n",
    "        current_time_array = np.expand_dims(current_time_array, axis=1)\n",
    "        #add to our dataset\n",
    "        if time_data is None:\n",
    "            time_data = current_time_array\n",
    "        else:\n",
    "            time_data = np.concatenate([time_data, current_time_array], axis=1)\n",
    "\n",
    "        #Get luminance data:\n",
    "        current_luminance_array = None\n",
    "        for chamber_idx in chamber_idxs:\n",
    "            #collect from DB\n",
    "            current_chamber_array = np.array(db_obj._json_dict[\"runs\"][run_name]['assays'][assay]['chambers'][chamber_idx]['sum_chamber'])\n",
    "            #set type to float:\n",
    "            current_chamber_array = current_chamber_array.astype(float)\n",
    "            #pad the array with NaNs if there are fewer time points than the max\n",
    "            current_chamber_array = np.pad(current_chamber_array, (0, max_time_points - len(current_chamber_array)), 'constant', constant_values=np.nan)\n",
    "            #sort by time:\n",
    "            current_chamber_array = current_chamber_array[sorting_idxs]\n",
    "            #add a dimension at the end:\n",
    "            current_chamber_array = np.expand_dims(current_chamber_array, axis=1)\n",
    "\n",
    "            if current_luminance_array is None:\n",
    "                current_luminance_array = current_chamber_array\n",
    "            else:\n",
    "                current_luminance_array = np.concatenate([current_luminance_array, current_chamber_array], axis=1)\n",
    "        #add a dimension at the end:\n",
    "        current_luminance_array = np.expand_dims(current_luminance_array, axis=2)\n",
    "        #add to our dataset\n",
    "        if luminance_data is None:\n",
    "            luminance_data = current_luminance_array\n",
    "        else:\n",
    "            luminance_data = np.concatenate([luminance_data, current_luminance_array], axis=2)\n",
    "        \n",
    "        #Get concentration data:\n",
    "        #collect from DB\n",
    "        current_conc = db_obj._json_dict[\"runs\"][run_name]['assays'][assay]['conc']\n",
    "        conc_data = np.append(conc_data, current_conc)\n",
    "\n",
    "    #sort once more, by conc_data:\n",
    "    sorting_idxs = np.argsort(conc_data)\n",
    "    conc_data = conc_data[sorting_idxs]\n",
    "\n",
    "    #sort luminance data by conc_data:\n",
    "    luminance_data = luminance_data[:,:,sorting_idxs]\n",
    "    \n",
    "    return chamber_idxs, luminance_data, conc_data, time_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot a chip using a given variable, with subplots:\n",
    "\n",
    "def plot_chip(plotting_var, chamber_names, graphing_function=None, title=None):\n",
    "    ''' This function creates a Dash visualization of a chip, based on a certain Run (run_name)\n",
    "        Inputs:\n",
    "            plotting_var: a dictionary mapping chamber_id to the variable to be plotted for that chamber\n",
    "            chamber_names: a dictionary mapping chamber_id to the name of the sample in the chamber (e.g. '1,1': ecADK_XYZ')\n",
    "            graphing_function: a function that takes in a single chamber_id (e.g. '1,1') and matplotlib axis and returns the axis object after plotting.\n",
    "            title: a string to be used as the title of the plot\n",
    "        TODO: make all the variables stored in Dash properly...\n",
    "    '''\n",
    "    from dash import Dash, dcc, html, Input, Output, no_update\n",
    "    import plotly.graph_objs as go\n",
    "    import base64\n",
    "    import tempfile\n",
    "\n",
    "    # Make the image array\n",
    "    #NB: eventually, store width/height in DB and reference!\n",
    "    img_array = np.zeros([56,32])\n",
    "\n",
    "    for chamber_id, value in plotting_var.items():\n",
    "        x = int(chamber_id.split(',')[0])\n",
    "        y = int(chamber_id.split(',')[1])\n",
    "        img_array[y-1,x-1] = value \n",
    "    \n",
    "    #generate title\n",
    "    if title is None:\n",
    "        title = ''\n",
    "    \n",
    "    #Create the figure\n",
    "    layout = go.Layout()\n",
    "    fig = go.Figure(layout=layout, data=go.Heatmap(z=img_array, colorscale='Viridis'))\n",
    "    #center title in fig\n",
    "    fig.update_layout(title=title,\n",
    "                        title_x=0.5, \n",
    "                        yaxis=dict(scaleanchor=\"x\", scaleratio=1, autorange='reversed'), \n",
    "                        xaxis=dict(scaleratio=1),\n",
    "                        plot_bgcolor='rgba(0,0,0,0)',\n",
    "                        width=600, height=600,\n",
    "                        hovermode='x')\n",
    "    fig.update_xaxes(showticklabels=False)\n",
    "    fig.update_yaxes(showticklabels=False)\n",
    "\n",
    "    #create dash app:\n",
    "    app = Dash(__name__)\n",
    "    app.layout = html.Div([\n",
    "        dcc.Graph(id=\"graph\", figure=fig, clear_on_unhover=True),\n",
    "        dcc.Tooltip(id=\"graph-tooltip\"),\n",
    "    ])\n",
    "\n",
    "    ### GRAPHING FUNCTION ON HOVER:\n",
    "    if graphing_function is not None:\n",
    "        @app.callback(\n",
    "            Output(\"graph-tooltip\", \"show\"),\n",
    "            Output(\"graph-tooltip\", \"bbox\"),\n",
    "            Output(\"graph-tooltip\", \"children\"),\n",
    "            Input(\"graph\", \"hoverData\"),\n",
    "        )\n",
    "        def display_hover(hoverData):\n",
    "            if hoverData is None:\n",
    "                return False, no_update, no_update\n",
    "            # demo only shows the first point, but other points may also be available\n",
    "            pt = hoverData[\"points\"][0]\n",
    "            chamber_id = str(pt['x']+1) + ',' + str(pt['y']+1)\n",
    "            bbox = pt[\"bbox\"]\n",
    "            chamber_name = chamber_names[chamber_id]\n",
    "            #get the data for the point:\n",
    "            fig, ax = plt.subplots()\n",
    "            ax = graphing_function(chamber_id, ax)\n",
    "            #reduce whitespace on margins of graph:\n",
    "            fig.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0, hspace=0)\n",
    "            #save the figure as a temp file:\n",
    "            tempfile_name = tempfile.NamedTemporaryFile().name+'.png'\n",
    "            plt.savefig(tempfile_name)\n",
    "            plt.close()\n",
    "            # #read in temp file as base64 encoded string:\n",
    "            with open(tempfile_name, \"rb\") as image_file:\n",
    "                img_src = \"data:image/png;base64,\" + str(base64.b64encode(image_file.read()).decode(\"utf-8\"))\n",
    "            children = [\n",
    "                html.Div(children=[\n",
    "                    #no space after header:\n",
    "                    html.H3('{},{}:  {}'.format(pt['x'], pt['y'], chamber_name), style={\"color\": 'black', \"fontFamily\":\"Arial\", \"textAlign\": \"center\", \"marginBottom\": \"0px\"}),\n",
    "                    #add the image with reduced whitespace:\n",
    "                    html.Img(src=img_src, style={\"width\": \"100%\"}),\n",
    "                ],\n",
    "                style={'width': '400px', 'white-space': 'none'})\n",
    "            ]\n",
    "\n",
    "            return True, bbox, children\n",
    "\n",
    "    app.run_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Connect DB Api\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from htbam_analysis.htbam_db_api import LocalHtbamDBAPI\n",
    "\n",
    "root = '/Users/duncanmuir/Desktop/20240426_adk_ortholog_inspection'\n",
    "db_conn = LocalHtbamDBAPI(standard_curve_data_path= '/Users/duncanmuir/Desktop/20240426_adk_ortholog_inspection/d1_NADPH_StandardSeries_Analysis.csv', standard_name=\"NADPH std curve\", standard_type=\"NADPH\", standard_units=\"uM\",\n",
    "                         kinetic_data_path= '/Users/duncanmuir/Desktop/20240426_adk_ortholog_inspection/20240117_titrationcsv_noFF.csv', kinetic_name=\"ADP kinetics curve\", kinetic_type=\"ADP\", kinetic_units=\"uM\")\n",
    "\n",
    "### TODO: Still want the following data in the database:\n",
    "# date (and time?) collected\n",
    "# operator name\n",
    "# Add additional descriptors\n",
    "# substrate_name\n",
    "# setup(?) and device_num\n",
    "# width/height\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format of DB:\n",
    "Useful? Or remove?\n",
    "DB\n",
    "- **chamber_metadata**\n",
    "    - '1,1'\n",
    "        - 'id'                  'organism_ADK'\n",
    "        - 'radius_chamber'      35.0\n",
    "        - 'x_center_chamber'    31.0\n",
    "        - 'y_center_chamber'    43.0\n",
    "        - 'xslice'              '(6758, 6805)'\n",
    "        - 'yslice'              '(6704, 6804)'\n",
    "    - ...\n",
    "    - '32,56' ...\n",
    "- **runs**\n",
    "    - 'standard_0'\n",
    "        - 'name'            'NAPDH_std_curve'\n",
    "        - 'type'            'NAPDH'\n",
    "        - 'conc_unit'       'uM'\n",
    "        - 'assays':\n",
    "            - 0:\n",
    "                - 'conc'\n",
    "                - 'time_s'\n",
    "                - 'chambers'\n",
    "                    - '1,1'\n",
    "                    - ...\n",
    "                    - '32,56' ...\n",
    "            - ...\n",
    "            - 6: ...\n",
    "        - 'analyses':\n",
    "            - 'linear_regression':\n",
    "                - 'chambers':\n",
    "                    - '1,1':\n",
    "                        - slope:\n",
    "                        - intercept:\n",
    "                        - r_value:\n",
    "                        - p_value: \n",
    "                        - std_err:\n",
    "                    - ...\n",
    "                    - '32,56'...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Standards\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each chamber, we've taken values at a set of concentrations. We need to perform a linear regression __for each chamber__ to relate the luminance of each chamber to its substrate concentration.\n",
    "\n",
    "In our hierarchical data structure, we will store this linear regression as an analysis under the standard curve experiment. It is stored under:\n",
    "\n",
    "```db_conn._json_dict['runs']['standard_0']['analyses']['linear_regression']```\n",
    "\n",
    "And it stores the data:\n",
    "```\n",
    "{'chambers':  {'1,1': \n",
    "                     {'intercept': ...,\n",
    "                      'p_value': ...,\n",
    "                      'r2': ...,\n",
    "                      'r_value': ...,\n",
    "                      'slope': ...,\n",
    "                      'std_err': ...,\n",
    "                     }\n",
    "               '1,2': {'intercept': ...}\n",
    "              }\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, we collect our data into numpy arrays\n",
    "chamber_idxs, luminance_data, conc_data, _ = assay_data_to_array(db_conn, 'standard_0')\n",
    "\n",
    "#shape should be (time x wells x assays) or (1, 1792, 7) in the example data (not true???)\n",
    "print('Luminance data shape:', luminance_data.shape)\n",
    "\n",
    "#Perform linear regression for each chamber:\n",
    "#and store immediately in 'database' object\n",
    "if 'analyses' not in db_conn._json_dict['runs']['standard_0'].keys():\n",
    "    db_conn._json_dict['runs']['standard_0']['analyses'] = {}\n",
    "\n",
    "db_conn._json_dict['runs']['standard_0']['analyses']['linear_regression'] = {'chambers': {}} #initialize the dictionary\n",
    "for i in range(len(chamber_idxs)):\n",
    "    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(conc_data, luminance_data[:,i])\n",
    "    db_conn._json_dict['runs']['standard_0']['analyses']['linear_regression']['chambers'][chamber_idxs[i]] = {'slope': slope, 'intercept': intercept, 'r_value': r_value, 'r2':r_value**2, 'p_value': p_value, 'std_err': std_err}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check:\n",
    "Now, let's sanity check by plotting. We can use the ```plot_chip()``` function to show a chip where each chamber is colored by variable (like luminance). We can also make subplots on hover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting variable: We'll plot by luminance. We need a dictionary mapping chamber id (e.g. '1,1') to the value to be plotted (e.g. slope)\n",
    "slopes_to_plot = {chamber_idx: db_conn._json_dict['runs']['standard_0']['analyses']['linear_regression']['chambers'][chamber_idx]['slope'] for chamber_idx in chamber_idxs}\n",
    "\n",
    "#chamber_names: We'll provide the name of the sample in each chamber as well, in the same way:\n",
    "chamber_names_dict = {chamber_idx: subdict['id'] for chamber_idx, subdict in db_conn._json_dict['chamber_metadata'].items()}\n",
    "\n",
    "#plotting function: We'll generate a subplot for each chamber, showing the raw data and the linear regression line.\n",
    "# to do this, we make a function that takes in the chamber_id and the axis object, and returns the axis object after plotting. Do NOT plot.show() in this function.\n",
    "def plot_chamber_slopes(chamber_id, ax):\n",
    "    #parameters:\n",
    "    run_name = 'standard_0'\n",
    "    analysis_name = 'linear_regression'\n",
    "    \n",
    "    #convert from 'x,y' to integer index in the array:\n",
    "    data_index = list(chamber_idxs).index(chamber_id)\n",
    "    x_data = conc_data\n",
    "    y_data = luminance_data[:,data_index]\n",
    "\n",
    "    #get slope from the analysis:\n",
    "    slope = np.array([db_conn._json_dict['runs'][run_name]['analyses'][analysis_name]['chambers'][chamber_idx]['slope'] for chamber_idx in chamber_idxs])\n",
    "    intercept = np.array([db_conn._json_dict['runs'][run_name]['analyses'][analysis_name]['chambers'][chamber_idx]['intercept'] for chamber_idx in chamber_idxs])\n",
    "    m = slope[data_index]\n",
    "    b = intercept[data_index]\n",
    "    #make a simple matplotlib plot\n",
    "    ax.scatter(x_data, y_data)\n",
    "    if not (np.isnan(m) or np.isnan(b)):\n",
    "        #return False, no_update, no_update\n",
    "        ax.plot(x_data, m*np.array(x_data) + b)\n",
    "    return ax\n",
    "\n",
    "\n",
    "### PLOT THE CHIP: now, we plot\n",
    "plot_chip(slopes_to_plot, chamber_names_dict, graphing_function=plot_chamber_slopes, title='Standard Curve: Slope')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit initial rates from processed kinetic data\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this next part, we'll be generating the predicted product concentration for each well, for each time, and for each substrate concentration. That's a 3D array.\n",
    "\n",
    "To do this, we divide our luminance value (in RFUs) by the slope of the chamber's standard curve (RFU/conc). Here, we ignore the standard curve intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gather kinetics data into numpy arrays\n",
    "chamber_idxs, luminance_data, conc_data, time_data = assay_data_to_array(db_conn, 'kinetics_0')\n",
    "print('Luminance data shape:', luminance_data.shape) #(time x wells x assays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each well contains time_series data. We have 32*56 wells (1792), and then N assays with different concentrations.\n",
    "So we have a np array with dimensions (time x wells x assays)\n",
    "For a standard, this will be (1, 1792, # concentrations)\n",
    "For a kinetics run, this will be (~20, 1792, # concentrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes = np.array([db_conn._json_dict['runs']['standard_0']['analyses']['linear_regression']['chambers'][chamber_idx]['slope'] for chamber_idx in chamber_idxs])\n",
    "\n",
    "#calculate product concentration by dividing every chamber intensity by the slope of the standard curve for that chamber\n",
    "product_concentration = luminance_data / slopes[np.newaxis, :, np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make numpy array of all button_quants with[ subtracted backgrounds:\n",
    "button_quant_no_background = [] #we will soon turn this into a numpy array\n",
    "for chamber_idx in chamber_idxs:\n",
    "    next_button_quant = db_conn._json_dict['button_quant'][chamber_idx]['summed_button_BGsub_Button_Quant']\n",
    "    button_quant_no_background.append(next_button_quant)\n",
    "button_quant_no_background = np.array(button_quant_no_background)\n",
    "\n",
    "# use eGFP standard curve to convert between button quant and eGFP concentration\n",
    "enzyme_concentration = button_quant_no_background / EGFP_SLOPE    #in units of EGFP_SLOPE_CONC_UNITS\n",
    "print('Enzyme concentration shape:', enzyme_concentration.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Fit initial rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###TODO:\n",
    "# 1) ~~I think addings nans kills the line fitting. Fix at some point. (in line fitting code, so we can keep nans?)~~\n",
    "#    Fixed? Appears like it's working properly.\n",
    "# 2) We're using the time values for the first chamber for all chambers. \n",
    "#    In practice, they're sometimes off by 1 second, which should not affect results much. Perhaps change in the future.\n",
    "# 3) Kinetics fails without substrate_conc, even though it says it's optional. Also prints an ugly array which we should disable.\n",
    "\n",
    "\n",
    "#make an array of initial slopes for each chamber: should be (#chambers , #concentrations) = (1792 x 11)\n",
    "initial_slopes = None\n",
    "initial_slopes_R2 = None\n",
    "initial_slopes_intercepts = None\n",
    "reg_idx_arr = None\n",
    "\n",
    "for i, chamber_idx in tqdm(list(enumerate(chamber_idxs))):\n",
    "\n",
    "    #use the kinetics package to calculate the slopes for this chamber at each substrate concentration.\n",
    "    current_chamber_slopes, current_chamber_R2, current_chamber_intercepts, current_chamber_reg_mask = kinetics.get_initial_slopes(time_data[:,0], product_concentration[:,i,:].T, substrate_concs=conc_data)\n",
    "\n",
    "    #add a dimension at the end:\n",
    "    current_chamber_slopes = np.expand_dims(current_chamber_slopes, axis=0)\n",
    "    current_chamber_R2 = np.expand_dims(current_chamber_R2, axis=0)\n",
    "    current_chamber_intercepts = np.expand_dims(current_chamber_intercepts, axis=0)\n",
    "    current_chamber_reg_mask = np.expand_dims(current_chamber_reg_mask, axis=0)\n",
    "    \n",
    "    #add to our complete array:\n",
    "    if initial_slopes is None:\n",
    "        initial_slopes = current_chamber_slopes\n",
    "        initial_slopes_R2 = current_chamber_R2\n",
    "        initial_slopes_intercepts = current_chamber_intercepts\n",
    "        reg_idx_arr = current_chamber_reg_mask\n",
    "    else:\n",
    "        initial_slopes = np.concatenate([initial_slopes, current_chamber_slopes], axis=0)\n",
    "        initial_slopes_R2 = np.concatenate([initial_slopes_R2, current_chamber_R2], axis=0)\n",
    "        initial_slopes_intercepts = np.concatenate([initial_slopes_intercepts, current_chamber_intercepts], axis=0)\n",
    "        reg_idx_arr = np.concatenate([reg_idx_arr, current_chamber_reg_mask], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RXN_PERC = 10\n",
    "STARTING_IDX = 1\n",
    "\n",
    "arr = np.empty((len(chamber_idxs), len(conc_data)))\n",
    "arr[:] = np.nan\n",
    "    \n",
    "#make an array of initial slopes for each chamber: should be (#chambers , #concentrations) = (1792 x 11)\n",
    "initial_slopes = arr.copy()\n",
    "initial_slopes_R2 = arr.copy()\n",
    "initial_slopes_intercepts = arr.copy()\n",
    "reg_idx_arr = np.zeros((len(chamber_idxs), len(conc_data), len(time_data))).astype(bool)\n",
    "print(reg_idx_arr.shape)\n",
    "\n",
    "time_series = time_data[:,0][:, np.newaxis]\n",
    "substrate_conc = conc_data\n",
    "\n",
    "product_thresholds = substrate_conc * MAX_RXN_PERC / 100\n",
    "product_thresholds[-1] /= 2 # ADK specific, we only have 1.2 mM NADP+\n",
    "product_thresholds = product_thresholds[:, np.newaxis]\n",
    "\n",
    "allowed_points = np.zeros_like(conc_data)\n",
    "for i, chamber_idx in tqdm(list(enumerate(chamber_idxs))):\n",
    "\n",
    "    #use the kinetics package to calculate the slopes for this chamber at each substrate concentration.\n",
    "    product_conc_array = product_concentration[:,i,:].T \n",
    "\n",
    "    # which product concentration is below the threshold?\n",
    "    rxn_threshold_mask = product_conc_array < product_thresholds\n",
    "    rxn_threshold_mask[:,:STARTING_IDX] = 0\n",
    "    allowed_points += (rxn_threshold_mask.sum(axis=1)>2)\n",
    "\n",
    "    slopes = np.zeros_like(conc_data)\n",
    "    intercepts = np.zeros_like(conc_data)\n",
    "    scores = np.zeros_like(conc_data)\n",
    "\n",
    "    for j, mask in enumerate(rxn_threshold_mask):\n",
    "        if mask.sum() < 2:\n",
    "            pass\n",
    "            #print(f'Chamber {chamber_idx} Concentration {conc_data[i]} uM has less than 2 points')\n",
    "        else:\n",
    "            lin_reg = LinearRegression()\n",
    "            lin_reg.fit(time_series[mask], product_conc_array[j,:][mask])\n",
    "            #print(time_series[mask], product_conc_array[i,:][mask])\n",
    "            slope, intercept, score = lin_reg.coef_, lin_reg.intercept_, lin_reg.score(time_series[mask], product_conc_array[j,:][mask])\n",
    "            #print(f'Concentration {conc_data[i]} uM has slope {slope} and intercept {intercept} with R2 {score}')\n",
    "            slopes[j] = slope\n",
    "            intercepts[j] = intercept\n",
    "            scores[j] = score\n",
    "\n",
    "    initial_slopes[i] = slopes\n",
    "    initial_slopes_intercepts[i] = intercepts\n",
    "    initial_slopes_R2[i] = scores\n",
    "    reg_idx_arr[i] = rxn_threshold_mask\n",
    "    \n",
    "\n",
    "  \n",
    "    \n",
    "\n",
    "perc_rxns_with_2_pts = (1792 - allowed_points) / 1792 * 100\n",
    "\n",
    "for sub_conc, perc in zip(conc_data, perc_rxns_with_2_pts):\n",
    "    print(f'{sub_conc:.2f} uM: {perc:.2f}% of reactions have less than 2 points')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot as before:\n",
    "#plotting variable: We'll plot by luminance. We need a dictionary mapping chamber id (e.g. '1,1') to the value to be plotted (e.g. slope)\n",
    "initial_rates_to_plot = {chamber_idxs[i]: np.nanmax(initial_slopes[i,:]) for i in range(len(chamber_idxs))}\n",
    "\n",
    "#chamber_names: Same as before.\n",
    "\n",
    "#plotting function: We'll generate a subplot for each chamber, showing the raw data and the linear regression line.\n",
    "# to do this, we make a function that takes in the chamber_id and the axis object, and returns the axis object after plotting. Do NOT plot.show() in this function.\n",
    "def plot_chamber_initial_rates(chamber_id, ax, time_to_plot=0.3):\n",
    "    #N.B. Every so often, slope and line colors don't match up. Not sure why.\n",
    "    \n",
    "    #convert from 'x,y' to integer index in the array:\n",
    "    data_index = list(chamber_idxs).index(chamber_id)\n",
    "    x_data = time_data[:,0]\n",
    "    y_data = product_concentration[:,data_index,:].T\n",
    "    \n",
    "    #plot only first X% of time:\n",
    "    max_time = np.nanmax(x_data)\n",
    "    time_to_plot = max_time*time_to_plot\n",
    "    time_idxs_to_plot = x_data < time_to_plot\n",
    "    x_data = x_data[time_idxs_to_plot]\n",
    "    y_data = y_data[:, time_idxs_to_plot]\n",
    "    \n",
    "    #get slope from the analysis:\n",
    "    current_chamber_slopes = initial_slopes[data_index,:]\n",
    "    #calculate y-intercept by making sure it intersects first point:\n",
    "    current_chamber_intercepts = initial_slopes_intercepts[data_index,:]\n",
    "    # get regressed point mask:\n",
    "    current_chamber_reg_mask = reg_idx_arr[data_index,:][:,:len(x_data)]\n",
    "    \n",
    "    colors = sns.color_palette('husl', n_colors=y_data.shape[0])\n",
    "\n",
    "    #print(y_data.shape[0])\n",
    "    for i in range(y_data.shape[0]): #over each concentration:\n",
    "        \n",
    "        ax.scatter(x_data, y_data[i,:], color=colors[i], alpha=0.3)\n",
    "        ax.scatter(x_data[current_chamber_reg_mask[i]], y_data[i, current_chamber_reg_mask[i]], color=colors[i], alpha=1, s=50)\n",
    "        \n",
    "        m = current_chamber_slopes[i]\n",
    "        b = current_chamber_intercepts[i]\n",
    "        if not (np.isnan(m) or np.isnan(b)):\n",
    "            #return False, no_update, no_update\n",
    "            ax.plot(x_data, m*np.array(x_data) + b, color=colors[i])\n",
    "    return ax\n",
    "\n",
    "\n",
    "### PLOT THE CHIP: now, we plot\n",
    "plot_chip(initial_rates_to_plot, chamber_names_dict, graphing_function=plot_chamber_initial_rates, title='Kinetics: Initial Rates (Max)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insp_idx = list(chamber_idxs).index(\"19,19\")\n",
    "insp_slopes = initial_slopes[insp_idx,:]\n",
    "insp_scores = initial_slopes_R2[insp_idx,:]\n",
    "insp_intercepts = initial_slopes_intercepts[insp_idx,:]\n",
    "\n",
    "time_to_plot=0.25\n",
    "\n",
    "x_data = time_data[:,0]\n",
    "y_data = product_concentration[:,insp_idx,:].T\n",
    "\n",
    "#plot only first X% of time:\n",
    "max_time = np.nanmax(x_data)\n",
    "time_to_plot = max_time*time_to_plot\n",
    "time_idxs_to_plot = x_data < time_to_plot\n",
    "x_data = x_data[time_idxs_to_plot]\n",
    "y_data = y_data[:, time_idxs_to_plot]\n",
    "insp_mask = reg_idx_arr[insp_idx,:][:,:len(x_data)]\n",
    "\n",
    "colors = sns.color_palette('husl', n_colors=y_data.shape[0])\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "#print(y_data.shape[0])\n",
    "for i in range(y_data.shape[0]): #over each concentration:\n",
    "    \n",
    "    if i < 4:\n",
    "        continue\n",
    "    ax[0].scatter(x_data, y_data[i,:], color=colors[i], alpha=0.3)\n",
    "    ax[0].scatter(x_data[insp_mask[i]], y_data[i, insp_mask[i]], color=colors[i], alpha=1, s=50, label=f'{conc_data[i]} uM')\n",
    "    \n",
    "    m = insp_slopes[i]\n",
    "    b = insp_intercepts[i]\n",
    "    if not (np.isnan(m) or np.isnan(b)):\n",
    "        #return False, no_update, no_update\n",
    "        ax[0].plot(x_data, m*np.array(x_data) + b, color=colors[i])\n",
    "ax[0].legend()\n",
    "ax[1].plot(conc_data, insp_slopes)\n",
    "ax[1].scatter(conc_data, insp_slopes)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_rate_plotting_data(idx):\n",
    "    slopes = initial_slopes[idx,:]\n",
    "    scores = initial_slopes_R2[idx,:]\n",
    "    intercepts = initial_slopes_intercepts[idx,:]\n",
    "    time_to_plot=0.25\n",
    "    x_data = time_data[:,0]\n",
    "    y_data = product_concentration[:,idx,:].T\n",
    "    #plot only first X% of time:\n",
    "    max_time = np.nanmax(x_data)\n",
    "    time_to_plot = max_time*time_to_plot\n",
    "    time_idxs_to_plot = x_data < time_to_plot\n",
    "    x_data = x_data[time_idxs_to_plot]\n",
    "    y_data = y_data[:, time_idxs_to_plot]\n",
    "    mask = reg_idx_arr[idx,:][:,:len(x_data)]\n",
    "    colors = [\"aqua\", \"crimson\", \"gold\", \"green\", \"blue\", \"purple\", \"orange\", \"pink\", \"brown\", \"black\", \"red\", \"cyan\", \"cornsilk\"]\n",
    "    colors = colors[:y_data.shape[0]]\n",
    "    return x_data, y_data, mask, colors, slopes, intercepts\n",
    "\n",
    "app = Dash(__name__)\n",
    "\n",
    "\n",
    "app.layout = html.Div([\n",
    "    \n",
    "    dcc.Markdown('''\n",
    "    ## Chamber Index:\n",
    "    ''',\n",
    "    style={'color': 'white', 'fontSize': 16, 'fontFamily': 'Arial'}),\n",
    "   \n",
    "    dcc.Input(\n",
    "        id='chamber_index',\n",
    "        placeholder='Enter a chamber index...',\n",
    "        type='number',\n",
    "        value=0\n",
    "    ),\n",
    "\n",
    "    dcc.Graph(id=\"graph\"),\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"graph\", \"figure\"), \n",
    "    Input(\"chamber_index\", \"value\"))\n",
    "def plot_initial_rates(idx):\n",
    "    x_data, y_data, mask, colors, slopes, intercepts = get_initial_rate_plotting_data(idx)\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for i in range(y_data.shape[0]):\n",
    "        fig.add_trace(go.Scatter(x=x_data, y=y_data[i,:], mode='markers', marker = {'color' : colors[i], 'opacity': 0.3}, showlegend=False))\n",
    "        fig.add_trace(go.Scatter(x=x_data[mask[i]], y=y_data[i, mask[i]], mode='markers', marker = {'color' : colors[i], 'size': 10}, name=f'{conc_data[i]} uM'))\n",
    "        fig.add_trace(go.Scatter(x=x_data, y=slopes[i]*x_data + intercepts[i], mode='lines', line = {'color' : colors[i]}, showlegend=False))\n",
    "    fig.update_layout(title=f'{chamber_names_dict[chamber_idxs[idx]]} ({chamber_idxs[idx]}): Progress Curve and Initial Rates',\n",
    "                      xaxis_title='Time (s)',\n",
    "                      yaxis_title='Product Concentration (uM)',\n",
    "                      # set figure size\n",
    "                        width=800,\n",
    "                        height=600)\n",
    "    return fig\n",
    "\n",
    "\n",
    "app.run_server(debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 8. Filter initial rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filters:\n",
    "We will filter by masking our product_concentration array with NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter threshholds ###\n",
    "\n",
    "#standard curve r^2 threshhold:\n",
    "r2_threshold = 0.98\n",
    "\n",
    "#enzyme expression threshhold:\n",
    "expression_threshhold = 1.5\n",
    "expression_threshhold_units = 'nM'\n",
    "\n",
    "#initial rate fit R^2 threshhold:\n",
    "intitial_rate_R2_threshhold = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make filters ###\n",
    "\n",
    "# STANDARD CURVE FILTER #\n",
    "# overwrite all chambers (rows) with r^2 values below the threshold with NaNs:\n",
    "filter_r2 = np.ones_like(initial_slopes)\n",
    "r2_values = np.array([db_conn._json_dict['runs']['standard_0']['analyses']['linear_regression']['chambers'][chamber_idx]['r2'] for chamber_idx in chamber_idxs])\n",
    "_count = 0\n",
    "for i, chamber_idx in enumerate(chamber_idxs):\n",
    "    if r2_values[i] < r2_threshold:\n",
    "        _count +=1\n",
    "        filter_r2[i, :] = np.nan\n",
    "print('Pearson r^2 filter: {}/{} chambers pass'.format(len(chamber_idxs)-_count, len(chamber_idxs)))\n",
    "\n",
    "# ENZYME EXPRESSION FILTER #\n",
    "# overwrite all chambers (rows) with enzyme expression below the threshold with NaNs:\n",
    "#Double check the expression units match the EGFP units:\n",
    "assert expression_threshhold_units == EGFP_SLOPE_CONC_UNITS, 'Error, enzyme expression and EGFP standard curve units do not match!'\n",
    "filter_enzyme_expression = np.ones_like(initial_slopes)\n",
    "_count = 0\n",
    "for i, chamber_idx in enumerate(chamber_idxs):\n",
    "    if enzyme_concentration[i] < expression_threshhold:\n",
    "        _count +=1\n",
    "        filter_enzyme_expression[i,:] = np.nan\n",
    "print('Enzyme expression filter: {}/{} chambers pass'.format(len(chamber_idxs)-_count, len(chamber_idxs)))\n",
    "\n",
    "# INITIAL RATE FIT FILTER #\n",
    "# overwrite just the assays per chamber (single values) with initial rate fit R^2 values below the threshold with NaNs:\n",
    "filter_initial_rate_R2 = np.ones_like(initial_slopes)\n",
    "_count = 0\n",
    "for i, chamber_idx in enumerate(chamber_idxs):\n",
    "    _chamber_count = 0\n",
    "    for j in range(len(conc_data)):\n",
    "        if initial_slopes_R2[i,j] < intitial_rate_R2_threshhold:\n",
    "            _chamber_count +=1\n",
    "            filter_initial_rate_R2[i,j] = np.nan\n",
    "    if len(conc_data) - _chamber_count < 10:\n",
    "        _count +=1\n",
    "print('Initial Rate R^2 filter: {}/{} chambers pass with 10 or more slopes.'.format(len(chamber_idxs)-_count, len(chamber_idxs)))\n",
    "\n",
    "# POSITIVE INITIAL SLOPE FILTER #\n",
    "# overwrite just the assays per chamber (single values) with initial slopes below zero with NaNs:\n",
    "filter_positive_initial_slope = np.ones_like(initial_slopes)\n",
    "_count = 0\n",
    "for i, chamber_idx in enumerate(chamber_idxs):\n",
    "    _chamber_count = 0\n",
    "    for j in range(len(conc_data)):\n",
    "        if initial_slopes[i,j] < 0:\n",
    "            _chamber_count +=1\n",
    "            filter_positive_initial_slope[i,j] = np.nan\n",
    "    if len(conc_data) - _chamber_count < 10:\n",
    "        _count +=1\n",
    "print('Positive Initial Slope filter: {}/{} chambers pass with 10 or more slopes.'.format(len(chamber_idxs)-_count, len(chamber_idxs)))\n",
    "\n",
    "\n",
    "### manually flagged wells ###\n",
    "#TODO: implement\n",
    "\n",
    "### TODO: make visualization!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter data ###\n",
    "#apply filters:\n",
    "filters = [filter_r2, filter_enzyme_expression, filter_initial_rate_R2, filter_positive_initial_slope]\n",
    "\n",
    "filtered_initial_slopes = deepcopy(initial_slopes)\n",
    "for filter in filters: filtered_initial_slopes *= filter\n",
    "\n",
    "#then, filter our enzyme concentration:\n",
    "enzyme_concentration_filtered = enzyme_concentration * filter_enzyme_expression[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chamber_idxs, luminance_data, conc_data, time_data\n",
    "\n",
    "#save filtered data to new analysis:\n",
    "if 'analyses' not in db_conn._json_dict['runs']['kinetics_0'].keys():\n",
    "    db_conn._json_dict['runs']['kinetics_0']['analyses'] = {}\n",
    "\n",
    "#initialize the dictionary\n",
    "db_conn._json_dict['runs']['kinetics_0']['analyses']['initial_slopes_filtered'] = {\n",
    "        'filters': ['filter_r2', 'filter_enzyme_expression', 'filter_initial_rate_R2', 'filter_positive_initial_slope'],\n",
    "        'filter_r2': r2_threshold,\n",
    "        'filter_enzyme_expression': expression_threshhold,\n",
    "        'filter_enzyme_expression_units': expression_threshhold_units,\n",
    "        'filter_initial_rate_R2': intitial_rate_R2_threshhold,\n",
    "        'filter_positive_initial_slope': True,\n",
    "        'assays': {}} \n",
    "\n",
    "for i in range(len(conc_data)):\n",
    "    db_conn._json_dict['runs']['kinetics_0']['analyses']['initial_slopes_filtered']['assays'][i] = {\n",
    "        'substrate_conc': conc_data[i],\n",
    "        'chambers': {}\n",
    "    }\n",
    "    for j, chamber_idx in enumerate(chamber_idxs):\n",
    "        db_conn._json_dict['runs']['kinetics_0']['analyses']['initial_slopes_filtered']['assays'][i]['chambers'][chamber_idx] = {\n",
    "            'slope': filtered_initial_slopes[j,i],\n",
    "            'r2': initial_slopes_R2[j,i]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###N.B.: May be some bug here, because some of the filtered-out chambers are still showing slopes.\n",
    "# I think they should have all nans...?\n",
    "\n",
    "#Let's plot as before:\n",
    "#plotting variable: We'll plot by luminance. We need a dictionary mapping chamber id (e.g. '1,1') to the value to be plotted (e.g. slope)\n",
    "filtered_initial_rates_to_plot = {chamber_idxs[i]: np.any(~np.isnan(filtered_initial_slopes[i,:])) for i in range(len(chamber_idxs))}\n",
    "\n",
    "#chamber_names: Same as before.\n",
    "\n",
    "#plotting function: We'll generate a subplot for each chamber, showing the raw data and the linear regression line.\n",
    "# to do this, we make a function that takes in the chamber_id and the axis object, and returns the axis object after plotting. Do NOT plot.show() in this function.\n",
    "def plot_chamber_filtered_initial_rates(chamber_id, ax):\n",
    "    #N.B. Every so often, slope and line colors don't match up. Not sure why.\n",
    "    #parameters: what amount of total time to plot? First 20%?\n",
    "    time_to_plot = 0.2\n",
    "    \n",
    "    #convert from 'x,y' to integer index in the array:\n",
    "    data_index = list(chamber_idxs).index(chamber_id)\n",
    "\n",
    "    x_data = time_data[:,0]\n",
    "    y_data = product_concentration[:,data_index,:].T\n",
    "    \n",
    "    #plot only first X% of time:\n",
    "    max_time = np.nanmax(x_data)\n",
    "    time_to_plot = max_time*time_to_plot\n",
    "    time_idxs_to_plot = x_data < time_to_plot\n",
    "    x_data = x_data[time_idxs_to_plot]\n",
    "    y_data = y_data[:, time_idxs_to_plot]\n",
    "    \n",
    "    #get slope from the analysis:\n",
    "    current_chamber_slopes = filtered_initial_slopes[data_index,:]\n",
    "    #calculate y-intercept by making sure it intersects first point:\n",
    "    current_chamber_intercepts = y_data[:,0] - current_chamber_slopes*x_data[0] #note: not true y-intercept from linear regression\n",
    "    \n",
    "    for i in range(y_data.shape[0]): #over each concentration:\n",
    "        ax.scatter(x_data, y_data[i,:])\n",
    "        m = current_chamber_slopes[i]\n",
    "        b = current_chamber_intercepts[i]\n",
    "        if not (np.isnan(m) or np.isnan(b)):\n",
    "            #return False, no_update, no_update\n",
    "            ax.plot(x_data, m*np.array(x_data) + b)\n",
    "    return ax\n",
    "\n",
    "\n",
    "### PLOT THE CHIP: now, we plot\n",
    "plot_chip(filtered_initial_rates_to_plot, chamber_names_dict, graphing_function=plot_chamber_filtered_initial_rates, title='Kinetics: Filtered Initial Rates (Max)')\n",
    "print('{}/1792 wells pass our filters.'.format( np.sum([x for x in filtered_initial_rates_to_plot.values()]) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Fit Michalis-Menten curves and visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important!** We must match our units for enzyme concentration with substrate concentration! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "substrate_conc_unit = db_conn._json_dict['runs']['kinetics_0']['conc_unit']\n",
    "if  substrate_conc_unit != EGFP_SLOPE_CONC_UNITS: print('Substrate concentration units do not match EGFP standard curve units! \\n{} != {}'.format(substrate_conc_unit, EGFP_SLOPE_CONC_UNITS))\n",
    "\n",
    "unit_converstion = 0.001 #convert FROM eGFP units TO substrate units (in this case, nM to uM)\n",
    "enzyme_concentration_converted_units = enzyme_concentration_filtered * unit_converstion\n",
    "\n",
    "#Double check!\n",
    "print('Conversion:')\n",
    "print('{} {} = {} {}  ?'.format(enzyme_concentration[0], EGFP_SLOPE_CONC_UNITS, enzyme_concentration_converted_units[0], substrate_conc_unit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, we calculate the Michaelis-Menten parameters for each chamber.\n",
    "\n",
    "K_i_array = np.array([])\n",
    "K_i_error_array = np.array([])\n",
    "\n",
    "for i in range(len(chamber_idxs)):\n",
    "    current_slopes = filtered_initial_slopes[i, :]\n",
    "\n",
    "    if np.all(np.isnan(current_slopes)):\n",
    "        print('Chamber {} has no slopes!'.format(chamber_idxs[i]))\n",
    "        K_i_array = np.append(K_i_array, np.nan)\n",
    "        K_i_error_array = np.append(K_i_error_array, np.nan)\n",
    "        continue\n",
    "\n",
    "    #get indices of non-nan values:\n",
    "    non_nan_idxs = np.where(~np.isnan(current_slopes))[0]\n",
    "    \n",
    "    current_slopes = current_slopes[non_nan_idxs]\n",
    "    current_concs = conc_data[non_nan_idxs]\n",
    "\n",
    "    if len(current_slopes) < 3:\n",
    "        print('Chamber {} has fewer than 3 slopes!'.format(chamber_idxs[i]))\n",
    "        K_i_array = np.append(K_i_array, np.nan)\n",
    "        K_i_error_array = np.append(K_i_error_array, np.nan)\n",
    "        continue\n",
    "    \n",
    "    #kinetics.fit_and_plot_micheaelis_menten(current_slopes, current_slopes, current_concs, enzyme_concentration_converted_units[i], 'uM', 'MM for first chamber!')\n",
    "    K_i, std_err = kinetics.fit_inhibition_constant(current_slopes, current_slopes, current_concs, enzyme_concentration_converted_units[i], 'uM', 'MM for first chamber!')\n",
    "    K_i_array = np.append(K_i_array, K_i)\n",
    "    K_i_error_array = np.append(K_i_error_array, std_err[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, we calculate the Michaelis-Menten parameters for each chamber.\n",
    "\n",
    "k_cat_array = np.array([])\n",
    "k_cat_error_array = np.array([])\n",
    "k_M_array = np.array([])\n",
    "k_M_error_array = np.array([])\n",
    "\n",
    "for i in range(len(chamber_idxs)):\n",
    "    current_slopes = filtered_initial_slopes[i, :]\n",
    "\n",
    "    if np.all(np.isnan(current_slopes)):\n",
    "        print('Chamber {} has no slopes!'.format(chamber_idxs[i]))\n",
    "        k_cat_array = np.append(k_cat_array, np.nan)\n",
    "        k_cat_error_array = np.append(k_cat_error_array, np.nan)\n",
    "        k_M_array = np.append(k_M_array, np.nan)\n",
    "        k_M_error_array = np.append(k_M_error_array, np.nan)\n",
    "        continue\n",
    "\n",
    "    #get indices of non-nan values:\n",
    "    non_nan_idxs = np.where(~np.isnan(current_slopes))[0]\n",
    "    \n",
    "    current_slopes = current_slopes[non_nan_idxs]\n",
    "    current_concs = conc_data[non_nan_idxs]\n",
    "\n",
    "    if len(current_slopes) < 3:\n",
    "        print('Chamber {} has fewer than 3 slopes!'.format(chamber_idxs[i]))\n",
    "        k_cat_array = np.append(k_cat_array, np.nan)\n",
    "        k_cat_error_array = np.append(k_cat_error_array, np.nan)\n",
    "        k_M_array = np.append(k_M_array, np.nan)\n",
    "        k_M_error_array = np.append(k_M_error_array, np.nan)\n",
    "        continue\n",
    "    \n",
    "    #kinetics.fit_and_plot_micheaelis_menten(current_slopes, current_slopes, current_concs, enzyme_concentration_converted_units[i], 'uM', 'MM for first chamber!')\n",
    "    k_cat, k_M, std_err = kinetics.fit_michaelis_menten(current_slopes, current_slopes, current_concs, enzyme_concentration_converted_units[i], 'uM', 'MM for first chamber!')\n",
    "    k_cat_array = np.append(k_cat_array, k_cat)\n",
    "    k_cat_error_array = np.append(k_cat_error_array, std_err[0])\n",
    "    k_M_array = np.append(k_M_array, k_M)\n",
    "    k_M_error_array = np.append(k_M_error_array, std_err[1])\n",
    "\n",
    "v_max_array = k_cat_array * enzyme_concentration_converted_units #in units of substrate_conc_unit\n",
    "v_max_error_array = k_cat_error_array * enzyme_concentration_converted_units #in units of substrate_conc_unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll save the raw Michaelis Menten paremters to a new analysis in the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chamber_idxs, luminance_data, conc_data, time_data\n",
    "\n",
    "#save filtered data to new analysis:\n",
    "if 'analyses' not in db_conn._json_dict['runs']['kinetics_0'].keys():\n",
    "    db_conn._json_dict['runs']['kinetics_0']['analyses'] = {}\n",
    "\n",
    "#initialize the dictionary\n",
    "db_conn._json_dict['runs']['kinetics_0']['analyses']['michaelis_menten_raw'] = {\n",
    "        'chambers': {}} \n",
    "\n",
    "for i, chamber_idx in enumerate(chamber_idxs):\n",
    "    db_conn._json_dict['runs']['kinetics_0']['analyses']['michaelis_menten_raw']['chambers'][chamber_idx] = {\n",
    "        'k_cat': k_cat_array[i],\n",
    "        'k_cat_error': k_cat_error_array[i],\n",
    "        'k_M': k_M_array[i],\n",
    "        'k_M_error': k_M_error_array[i],\n",
    "        'v_max': v_max_array[i],\n",
    "        'v_max_error': v_max_error_array[i]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we've kept the Michaelis-Menten parameters grouped into their wells. Since we've run several replicates in different wells, we'll group them here by replicate, using the 'id' value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get chamber ids from metadata:\n",
    "chamber_name_to_idx = {}\n",
    "for chamber_idx, subdict in db_conn._json_dict['chamber_metadata'].items():\n",
    "    name = subdict['id']\n",
    "    if name not in chamber_name_to_idx.keys():\n",
    "        chamber_name_to_idx[name] = [chamber_idx]\n",
    "    else:\n",
    "        chamber_name_to_idx[name].append(chamber_idx)\n",
    "\n",
    "#get average number of replicates:\n",
    "n_replicates = np.mean([len(x) for x in chamber_name_to_idx.values()])\n",
    "print('Average number of replicates per sample: {}'.format(np.round(n_replicates, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we gather and filter our MM-data. What z-score would we like to use to distinguish outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score_threshhold_MM = 1.5\n",
    "z_score_threshhold_expression = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get average k_cat, k_M, and v_max for each sample:\n",
    "sample_names = np.array([])\n",
    "sample_k_cat = np.array([])\n",
    "sample_k_cat_error = np.array([])\n",
    "sample_k_cat_replicates = []\n",
    "sample_k_M = np.array([])           #in units of substrate_conc_unit\n",
    "sample_k_M_error = np.array([])\n",
    "sample_k_M_replicates = []\n",
    "sample_v_max = np.array([])         #in units of substrate_conc_unit\n",
    "sample_v_max_error = np.array([])\n",
    "sample_v_max_replicates = []\n",
    "\n",
    "#Get z-scores for each well (used to filter in the next step!)\n",
    "k_cat_zscores = np.array([])\n",
    "k_M_zscores = np.array([])\n",
    "v_max_zscores = np.array([])\n",
    "enzyme_concentration_zscores = np.array([])\n",
    "\n",
    "#For each sample, \n",
    "for name, ids in chamber_name_to_idx.items():\n",
    "\n",
    "    ### GATHER MM PARAMETERS OF REPLICATES FOR EACH SAMPLE: ###\n",
    "    #get indices of idxs in chamber_idxs:\n",
    "    idxs = [list(chamber_idxs).index(x) for x in ids]\n",
    "\n",
    "    #get values for those indices:\n",
    "    k_cat = k_cat_array[idxs]\n",
    "    k_M = k_M_array[idxs]\n",
    "    v_max = v_max_array[idxs]\n",
    "    #keep track of which wells we exclude later:\n",
    "    k_cat_replicates = np.array(ids)\n",
    "    k_M_replicates = np.array(ids)\n",
    "    v_max_replicates = np.array(ids)\n",
    "\n",
    "    #if any of these is all nans, just continue to avoid errors:\n",
    "    if np.all(np.isnan(k_cat)) or np.all(np.isnan(k_M)) or np.all(np.isnan(v_max)):\n",
    "        print('No values from sample {}, all pre-filtered.'.format(name))\n",
    "        continue\n",
    "\n",
    "    ### FILTER OUT OUTLIERS: ###\n",
    "    #calculate z-score for each value:\n",
    "    k_cat_zscore = (k_cat - np.nanmean(k_cat))/np.nanstd(k_cat)\n",
    "    k_M_zscore = (k_M - np.nanmean(k_M))/np.nanstd(k_M)\n",
    "    v_max_zscore = (v_max - np.nanmean(v_max))/np.nanstd(v_max)\n",
    "    #also, get z-score of enzyme expression for each well:\n",
    "    enzyme_concentration_zscore = (enzyme_concentration_converted_units[idxs] - np.nanmean(enzyme_concentration_converted_units[idxs]))/np.nanstd(enzyme_concentration_converted_units[idxs]) #in units of 'substrate_conc_unit' \n",
    "\n",
    "    #First, for enzyme expression outliers, set the value to NaN to be filtered in the final step:\n",
    "    k_cat[np.abs(enzyme_concentration_zscore) > z_score_threshhold_expression] = np.nan\n",
    "    k_M[np.abs(enzyme_concentration_zscore) > z_score_threshhold_expression] = np.nan\n",
    "    v_max[np.abs(enzyme_concentration_zscore) > z_score_threshhold_expression] = np.nan\n",
    "\n",
    "    #filter out values with z-score > threshhold:\n",
    "    k_cat = k_cat[np.abs(k_cat_zscore) < z_score_threshhold_MM]\n",
    "    k_M = k_M[np.abs(k_M_zscore) < z_score_threshhold_MM]\n",
    "    v_max = v_max[np.abs(v_max_zscore) < z_score_threshhold_MM]\n",
    "    #do the same for the replicates ids:\n",
    "    k_cat_replicates = k_cat_replicates[np.abs(k_cat_zscore) < z_score_threshhold_MM]\n",
    "    k_M_replicates = k_M_replicates[np.abs(k_M_zscore) < z_score_threshhold_MM]\n",
    "    v_max_replicates = v_max_replicates[np.abs(v_max_zscore) < z_score_threshhold_MM]\n",
    "\n",
    "    #remove nan values from all (nan values are due to both no experimental data, and z-score filtering)\n",
    "    k_cat_replicates = k_cat_replicates[~np.isnan(k_cat)]\n",
    "    k_M_replicates = k_M_replicates[~np.isnan(k_M)]\n",
    "    v_max_replicates = v_max_replicates[~np.isnan(v_max)]\n",
    "    k_cat = k_cat[~np.isnan(k_cat)]\n",
    "    k_M = k_M[~np.isnan(k_M)]\n",
    "    v_max = v_max[~np.isnan(v_max)]\n",
    "\n",
    "    if len(k_cat) < 3:\n",
    "        print('Not enough replicates for sample {}. Skipping.'.format(name))\n",
    "        continue\n",
    "    \n",
    "    #get average values:\n",
    "    sample_names = np.append(sample_names, name)\n",
    "    sample_k_cat = np.append(sample_k_cat, np.mean(k_cat))\n",
    "    sample_k_cat_error = np.append(sample_k_cat_error,np.std(k_cat))\n",
    "    sample_k_M = np.append(sample_k_M, np.mean(k_M))\n",
    "    sample_k_M_error = np.append(sample_k_M_error, np.std(k_M))\n",
    "    sample_v_max = np.append(sample_v_max, np.mean(v_max))\n",
    "    sample_v_max_error = np.append(sample_v_max_error, np.std(v_max))\n",
    "    #keep track of replicates:\n",
    "    sample_k_cat_replicates.append(k_cat_replicates)\n",
    "    sample_k_M_replicates.append(k_M_replicates)\n",
    "    sample_v_max_replicates.append(v_max_replicates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we add this to the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save filtered data to new analysis:\n",
    "if 'analyses' not in db_conn._json_dict['runs']['kinetics_0'].keys():\n",
    "    db_conn._json_dict['runs']['kinetics_0']['analyses'] = {}\n",
    "\n",
    "#initialize the dictionary\n",
    "db_conn._json_dict['runs']['kinetics_0']['analyses']['michaelis_menten_filtered'] = {\n",
    "        'samples': {}} \n",
    "\n",
    "for i, sample_name in enumerate(sample_names):\n",
    "    db_conn._json_dict['runs']['kinetics_0']['analyses']['michaelis_menten_filtered']['samples'][sample_name] = {\n",
    "        'k_cat': sample_k_cat[i],\n",
    "        'k_cat_error': sample_k_cat_error[i],\n",
    "        'k_cat_replicates': sample_k_cat_replicates[i],\n",
    "        'k_M': sample_k_M[i],\n",
    "        'k_M_error': sample_k_M_error[i],\n",
    "        'k_M_replicates': sample_k_M_replicates[i],\n",
    "        'v_max': sample_v_max[i],\n",
    "        'v_max_error': sample_v_max_error[i],\n",
    "        'v_max_replicates': sample_v_max_replicates[i]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize:\n",
    "#plotting variable: We'll plot by K_M. We need a dictionary mapping chamber id (e.g. '1,1') to the value to be plotted\n",
    "#first, fill it with NaNs as a placeholder:\n",
    "k_M_to_plot = {chamber_idx: np.nan for chamber_idx in chamber_idxs}\n",
    "#then, fill in the values we have:\n",
    "for i in range(len(sample_names)):\n",
    "    for chamber_idx in chamber_name_to_idx[sample_names[i]]:\n",
    "        k_M_to_plot[chamber_idx] = sample_k_M[i]\n",
    "\n",
    "#plotting function: We'll generate an MM subplot for each chamber.\n",
    "def plot_chamber_MM(chamber_id, ax):\n",
    "    #find the name of the chamber:\n",
    "    chamber_name = chamber_names_dict[chamber_id]\n",
    "    #first, find all chambers with this name:\n",
    "    #if there's no data, just skip!\n",
    "    if chamber_name not in db_conn._json_dict['runs']['kinetics_0']['analyses']['michaelis_menten_filtered']['samples']:\n",
    "        return ax\n",
    "    chamber_id_list = db_conn._json_dict['runs']['kinetics_0']['analyses']['michaelis_menten_filtered']['samples'][chamber_name]['k_M_replicates']\n",
    "\n",
    "    #convert to array indices:\n",
    "    chamber_id_list = [list(chamber_idxs).index(x) for x in chamber_id_list]\n",
    "\n",
    "    #get the initial rates for each chamber:\n",
    "    initial_slopes = filtered_initial_slopes[chamber_id_list,:]\n",
    "    #get average\n",
    "    initial_slopes_avg = np.nanmean(initial_slopes, axis=0)\n",
    "    #get error bars\n",
    "    initial_slopes_std = np.nanstd(initial_slopes, axis=0)\n",
    "\n",
    "    #get the substrate concentrations that match with each initial rate:\n",
    "    substrate_concs = conc_data\n",
    "\n",
    "    x_data = substrate_concs\n",
    "    y_data = initial_slopes_avg\n",
    "\n",
    "    #plot with error bars:\n",
    "    ax.errorbar(x_data, y_data, yerr=initial_slopes_std, fmt='o')\n",
    "    \n",
    "    return ax\n",
    "\n",
    "#chamber_names: We'll provide the name of the sample in each chamber as well, in the same way:\n",
    "chamber_names_dict = {chamber_idx: subdict['id'] for chamber_idx, subdict in db_conn._json_dict['chamber_metadata'].items()}\n",
    "\n",
    "### PLOT THE CHIP: now, we plot\n",
    "plot_chip(k_M_to_plot, chamber_names_dict, graphing_function=plot_chamber_MM, title='Filtered K_M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Idea: Once we have initial fit for KM, have a view that flags each well by substrate \"coverage\":\n",
    "#that is, whether our experiment had 1/10th and 10x substrate concentration than Vmax\n",
    "# In the future, add a way to include more metadata like optimal growth temperature and full organism name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.a. Export to CSV in format people like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary CSV, showing data for each SAMPLE:\n",
    "output_csv_name = '/Users/GarrisonsMac/cool_kinetics_summary'\n",
    "\n",
    "import csv\n",
    "with open(output_csv_name+'_short.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    #write header:\n",
    "    writer.writerow(['id', \n",
    "                     'substrate_name', \n",
    "                     'assay_type', \n",
    "                     'replicates', \n",
    "                     'kcat_mean_filtered', \n",
    "                     'kcat_stdev_filtered', \n",
    "                     'Km_mean_filtered', \n",
    "                     'Km_stdev_filtered', \n",
    "                     'enzyme', \n",
    "                     'vmax_mean_filtered', \n",
    "                     'vmax_stdev_filtered'])\n",
    "    #write data:\n",
    "    for i, sample_name in enumerate(sample_names):\n",
    "        #get the chamber indices for this sample:\n",
    "        chamber_indices = np.where(np.isin(chamber_idxs, chamber_name_to_idx[sample_name]))[0]\n",
    "        #get average enzyme conc:\n",
    "        enzyme_conc = np.nanmean(enzyme_concentration_converted_units[chamber_indices])\n",
    "        row = [sample_name,\n",
    "               sample_name,\n",
    "               db_conn._json_dict['runs']['kinetics_0']['type'], \n",
    "               len(sample_k_cat_replicates[i]), \n",
    "               sample_k_cat[i], \n",
    "               sample_k_cat_error[i], \n",
    "               sample_k_M[i], \n",
    "               sample_k_M_error[i], \n",
    "               enzyme_conc,\n",
    "               sample_v_max[i], \n",
    "               sample_v_max_error[i]]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full CSV, showing data for each CHAMBER:\n",
    "output_csv_name = '/Users/GarrisonsMac/cool_kinetics_full_data'\n",
    "\n",
    "import csv\n",
    "with open(output_csv_name+'.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    #write header:\n",
    "    writer.writerow(['id', \n",
    "                     'x,y',\n",
    "                     'substrate_name', \n",
    "                     'assay_type', \n",
    "                     'replicates', \n",
    "                     'kcat', \n",
    "                     'kcat_mean_filtered', \n",
    "                     'kcat_stdev_filtered', \n",
    "                     'Km', \n",
    "                     'Km_mean_filtered', \n",
    "                     'Km_stdev_filtered', \n",
    "                     'enzyme',\n",
    "                     'vmax', \n",
    "                     'vmax_mean_filtered', \n",
    "                     'vmax_stdev_filtered'])\n",
    "    #write data for each chamber:\n",
    "    for i, chamber_idx in enumerate(chamber_idxs):\n",
    "        sample_name = chamber_names_dict[chamber_idx]\n",
    "        #get index in sample_names:\n",
    "        if sample_name in sample_names:\n",
    "            sample_idx = list(sample_names).index(sample_name)\n",
    "            row = [chamber_names_dict[chamber_idx], #id\n",
    "                    chamber_idx, #x,y\n",
    "                    sample_name, #substrate_name\n",
    "                    db_conn._json_dict['runs']['kinetics_0']['type'], #assay_type\n",
    "                    len(sample_k_cat_replicates[sample_idx]), #replicates\n",
    "                    db_conn._json_dict['runs']['kinetics_0']['analyses']['michaelis_menten_raw']['chambers'][chamber_idx]['k_cat'], #kcat\n",
    "                    sample_k_cat[sample_idx], #kcat_mean_filtered\n",
    "                    sample_k_cat_error[sample_idx], #kcat_stdev_filtered\n",
    "                    db_conn._json_dict['runs']['kinetics_0']['analyses']['michaelis_menten_raw']['chambers'][chamber_idx]['k_M'], #Km\n",
    "                    sample_k_M[sample_idx], #Km_mean_filtered\n",
    "                    sample_k_M_error[sample_idx], #Km_stdev_filtered\n",
    "                    enzyme_concentration_converted_units[i], #enzyme\n",
    "                    db_conn._json_dict['runs']['kinetics_0']['analyses']['michaelis_menten_raw']['chambers'][chamber_idx]['v_max'], #vmax\n",
    "                    sample_v_max[sample_idx], #vmax_mean_filtered\n",
    "                    sample_v_max_error[sample_idx]] #vmax_stdev_filtered\n",
    "        else:\n",
    "            row = [chamber_names_dict[chamber_idx], #id\n",
    "                    chamber_idx, #x,y\n",
    "                    sample_name, #substrate_name\n",
    "                    db_conn._json_dict['runs']['kinetics_0']['type'], #assay_type\n",
    "                    'NaN', #replicates\n",
    "                    db_conn._json_dict['runs']['kinetics_0']['analyses']['michaelis_menten_raw']['chambers'][chamber_idx]['k_cat'], #kcat\n",
    "                    'NaN', #kcat_mean_filtered\n",
    "                    'NaN', #kcat_stdev_filtered\n",
    "                    db_conn._json_dict['runs']['kinetics_0']['analyses']['michaelis_menten_raw']['chambers'][chamber_idx]['k_M'], #Km\n",
    "                    'NaN', #Km_mean_filtered\n",
    "                    'NaN', #Km_stdev_filtered\n",
    "                    enzyme_concentration_converted_units[i], #enzyme\n",
    "                    db_conn._json_dict['runs']['kinetics_0']['analyses']['michaelis_menten_raw']['chambers'][chamber_idx]['v_max'], #vmax\n",
    "                    'NaN', #vmax_mean_filtered\n",
    "                    'NaN' #vmax_stdev_filtered\n",
    "            ]\n",
    "        \n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('htbam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "5251e5d527c27e578782093071857f9d35d4116867e1a94829f633618c7ec13f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
