{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Template\n",
    "WIP new analysis template. Only to be used with most recent version of kinetics package as of 11/21/23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enables autoreloding of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#MISSING PACKAGES: plotly, dash, pint\n",
    "\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import skimage\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from pathlib import Path \n",
    "from htbam_db_api.htbam_db_api import LocalHtbamDBAPI\n",
    "\n",
    "#Import Kinetics Package for line fitting:\n",
    "import kinetics\n",
    "from kinetics.chip import analysis, visualization\n",
    "\n",
    "import pint\n",
    "\n",
    "#Configuration settings for pandas and seaborn\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "#sns.set(style='ticks', context='paper', font_scale=1.2, rc={\"lines.linewidth\": 1.2})\n",
    "\n",
    "#enable inline plotting of matplotlib figures\n",
    "%matplotlib inline\n",
    "\n",
    "#set the figure format to SVG\n",
    "%config InlineBackend.figure_format = 'svg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define our UNITS:\n",
    "ureg = pint.UnitRegistry()\n",
    "ureg.define('RFU = [luminosity]')\n",
    "\n",
    "### SLOPE OF THE STANDARD CURVE\n",
    "EGFP_SLOPE = 91900.03 * ureg('RFU/nM')\n",
    "# def assay_data_to_array(db_obj, run_name):\n",
    "#     '''This function takes as input an HTBAM Database object.\n",
    "#     For each kinetics run, we have \n",
    "#     It returns 3 numpy arrays:\n",
    "#     chamber_ids: an array of the chamber ids (in the format '1,1' ... '32,56')\n",
    "#         shape: (n_chambers,)\n",
    "#     luminance_data: an array of the luminance data for each chamber\n",
    "#         shape: (n_time_points, n_chambers, n_assays)\n",
    "#     conc_data: an array of the concentration data for each chamber.\n",
    "#         shape: (n_assays,)\n",
    "#     time_data: an array of the time data for each time point.\n",
    "#         shape: (n_time_points, n_assays)\n",
    "#     '''\n",
    "    \n",
    "#     chamber_idxs = np.array(list(db_obj._json_dict['chamber_metadata'].keys()))\n",
    "#     luminance_data = None\n",
    "#     time_data = None\n",
    "#     conc_data = np.array([])\n",
    "\n",
    "#     #Each assay may have recorded a different # of time points.\n",
    "#     #First, we'll just check what the max # of time points is:\n",
    "#     max_time_points = 0\n",
    "#     for assay in db_obj._json_dict[\"runs\"][run_name]['assays'].keys():\n",
    "#         current_assay_time_points = len(np.array(db_obj._json_dict[\"runs\"][run_name]['assays'][assay]['time_s']))\n",
    "#         if current_assay_time_points > max_time_points:\n",
    "#             max_time_points = current_assay_time_points\n",
    "\n",
    "#     for assay in db_obj._json_dict[\"runs\"][run_name]['assays'].keys():\n",
    "        \n",
    "#         #to make things easier later, we'll be sorting the datapoints by time value.\n",
    "#         #Get time data:\n",
    "#         #collect from DB\n",
    "#         current_time_array = np.array(db_obj._json_dict[\"runs\"][run_name]['assays'][assay]['time_s'])\n",
    "#         current_time_array = current_time_array.astype(float) #so we can pad with NaNs\n",
    "#         #pad the array with NaNs if there are fewer time points than the max\n",
    "#         current_time_array = np.pad(current_time_array, (0, max_time_points - len(current_time_array)), 'constant', constant_values=np.nan)\n",
    "#         #sort, and capture sorting idxs:\n",
    "#         sorting_idxs = np.argsort(current_time_array)\n",
    "#         current_time_array = current_time_array[sorting_idxs]\n",
    "#         current_time_array = np.expand_dims(current_time_array, axis=1)\n",
    "#         #add to our dataset\n",
    "#         if time_data is None:\n",
    "#             time_data = current_time_array\n",
    "#         else:\n",
    "#             time_data = np.concatenate([time_data, current_time_array], axis=1)\n",
    "\n",
    "#         #Get luminance data:\n",
    "#         current_luminance_array = None\n",
    "#         for chamber_idx in chamber_idxs:\n",
    "#             #collect from DB\n",
    "#             current_chamber_array = np.array(db_obj._json_dict[\"runs\"][run_name]['assays'][assay]['chambers'][chamber_idx]['sum_chamber'])\n",
    "#             #set type to float:\n",
    "#             current_chamber_array = current_chamber_array.astype(float)\n",
    "#             #pad the array with NaNs if there are fewer time points than the max\n",
    "#             current_chamber_array = np.pad(current_chamber_array, (0, max_time_points - len(current_chamber_array)), 'constant', constant_values=np.nan)\n",
    "#             #sort by time:\n",
    "#             current_chamber_array = current_chamber_array[sorting_idxs]\n",
    "#             #add a dimension at the end:\n",
    "#             current_chamber_array = np.expand_dims(current_chamber_array, axis=1)\n",
    "\n",
    "#             if current_luminance_array is None:\n",
    "#                 current_luminance_array = current_chamber_array\n",
    "#             else:\n",
    "#                 current_luminance_array = np.concatenate([current_luminance_array, current_chamber_array], axis=1)\n",
    "#         #add a dimension at the end:\n",
    "#         current_luminance_array = np.expand_dims(current_luminance_array, axis=2)\n",
    "#         #add to our dataset\n",
    "#         if luminance_data is None:\n",
    "#             luminance_data = current_luminance_array\n",
    "#         else:\n",
    "#             luminance_data = np.concatenate([luminance_data, current_luminance_array], axis=2)\n",
    "        \n",
    "#         #Get concentration data:\n",
    "#         #collect from DB\n",
    "#         current_conc = db_obj._json_dict[\"runs\"][run_name]['assays'][assay]['conc']\n",
    "#         conc_data = np.append(conc_data, current_conc)\n",
    "\n",
    "#     #sort once more, by conc_data:\n",
    "#     sorting_idxs = np.argsort(conc_data)\n",
    "#     conc_data = conc_data[sorting_idxs]\n",
    "\n",
    "#     #sort luminance data by conc_data:\n",
    "#     luminance_data = luminance_data[:,:,sorting_idxs]\n",
    "    \n",
    "#     return chamber_idxs, luminance_data, conc_data, time_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot a chip using a given variable, with subplots:\n",
    "\n",
    "def plot_chip(plotting_var, chamber_names, graphing_function=None, title=None):\n",
    "    ''' This function creates a Dash visualization of a chip, based on a certain Run (run_name)\n",
    "        Inputs:\n",
    "            plotting_var: a dictionary mapping chamber_id to the variable to be plotted for that chamber\n",
    "            chamber_names: a dictionary mapping chamber_id to the name of the sample in the chamber (e.g. '1,1': ecADK_XYZ')\n",
    "            graphing_function: a function that takes in a single chamber_id (e.g. '1,1') and matplotlib axis and returns the axis object after plotting.\n",
    "            title: a string to be used as the title of the plot\n",
    "        TODO: make all the variables stored in Dash properly...\n",
    "    '''\n",
    "    from dash import Dash, dcc, html, Input, Output, no_update\n",
    "    import plotly.graph_objs as go\n",
    "    import base64\n",
    "    import tempfile\n",
    "\n",
    "    # Make the image array\n",
    "    #NB: eventually, store width/height in DB and reference!\n",
    "    img_array = np.zeros([56,32])\n",
    "\n",
    "    for chamber_id, value in plotting_var.items():\n",
    "        x = int(chamber_id.split(',')[0])\n",
    "        y = int(chamber_id.split(',')[1])\n",
    "        img_array[y-1,x-1] = value \n",
    "    \n",
    "    #generate title\n",
    "    if title is None:\n",
    "        title = ''\n",
    "    \n",
    "    #Create the figure\n",
    "    layout = go.Layout()\n",
    "    fig = go.Figure(layout=layout, data=go.Heatmap(z=img_array, colorscale='Viridis'))\n",
    "    #center title in fig\n",
    "    fig.update_layout(title=title,\n",
    "                        title_x=0.5, \n",
    "                        yaxis=dict(scaleanchor=\"x\", scaleratio=1, autorange='reversed'), \n",
    "                        xaxis=dict(scaleratio=1),\n",
    "                        plot_bgcolor='rgba(0,0,0,0)',\n",
    "                        width=600, height=600,\n",
    "                        hovermode='x')\n",
    "    fig.update_xaxes(showticklabels=False)\n",
    "    fig.update_yaxes(showticklabels=False)\n",
    "\n",
    "    #create dash app:\n",
    "    app = Dash(__name__)\n",
    "    app.layout = html.Div([\n",
    "        dcc.Graph(id=\"graph\", figure=fig, clear_on_unhover=True),\n",
    "        dcc.Tooltip(id=\"graph-tooltip\"),\n",
    "    ])\n",
    "\n",
    "    ### GRAPHING FUNCTION ON HOVER:\n",
    "    if graphing_function is not None:\n",
    "        @app.callback(\n",
    "            Output(\"graph-tooltip\", \"show\"),\n",
    "            Output(\"graph-tooltip\", \"bbox\"),\n",
    "            Output(\"graph-tooltip\", \"children\"),\n",
    "            Input(\"graph\", \"hoverData\"),\n",
    "        )\n",
    "        def display_hover(hoverData):\n",
    "            if hoverData is None:\n",
    "                return False, no_update, no_update\n",
    "            # demo only shows the first point, but other points may also be available\n",
    "            pt = hoverData[\"points\"][0]\n",
    "            chamber_id = str(pt['x']+1) + ',' + str(pt['y']+1)\n",
    "            bbox = pt[\"bbox\"]\n",
    "            chamber_name = chamber_names[chamber_id]\n",
    "            #get the data for the point:\n",
    "            fig, ax = plt.subplots()\n",
    "            ax = graphing_function(chamber_id, ax)\n",
    "            #reduce whitespace on margins of graph:\n",
    "            fig.subplots_adjust(left=0.2, bottom=0.1, right=0.9, top=0.9, wspace=0, hspace=0)\n",
    "            #save the figure as a temp file:\n",
    "            tempfile_name = tempfile.NamedTemporaryFile().name+'.png'\n",
    "            plt.savefig(tempfile_name)\n",
    "            plt.close()\n",
    "            # #read in temp file as base64 encoded string:\n",
    "            with open(tempfile_name, \"rb\") as image_file:\n",
    "                img_src = \"data:image/png;base64,\" + str(base64.b64encode(image_file.read()).decode(\"utf-8\"))\n",
    "            children = [\n",
    "                html.Div(children=[\n",
    "                    #no space after header:\n",
    "                    html.H3('{},{}:  {}'.format(pt['x'], pt['y'], chamber_name), style={\"color\": 'black', \"fontFamily\":\"Arial\", \"textAlign\": \"center\", \"marginBottom\": \"0px\"}),\n",
    "                    #add the image with reduced whitespace:\n",
    "                    html.Img(src=img_src, style={\"width\": \"90%\"}),\n",
    "                ],\n",
    "                style={'width': '400px', 'white-space': 'none'})\n",
    "            ]\n",
    "\n",
    "            return True, bbox, children\n",
    "\n",
    "    app.run_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Connect DB Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: add proper file path parsing\n",
    "\n",
    "root = '../local_test_data/garrison/'\n",
    "root = Path(root)\n",
    "db = HTBAM_Experiment('test_exp.HTBAM', new=True, units_registry=ureg)\n",
    "print(db.get(''))\n",
    "\n",
    "#load standards, kinetics, and button quant:\n",
    "db.load_standard_data_from_file(\n",
    "    standard_curve_data_path= root/'d2_5_StandardSeries_Analysis.csv.bz2', \n",
    "    standard_name=\"NADPH std curve\", \n",
    "    standard_type=\"NADPH\", \n",
    "    standard_units=\"uM\",)\n",
    "db.load_kinetics_data_from_file(\n",
    "    kinetic_data_path= root/'d2_TitrationSeries_Analysis.csv.bz2', \n",
    "    kinetic_name=\"NADPH kinetics curve\", \n",
    "    kinetic_type=\"NADPH\", \n",
    "    kinetic_units=\"uM\")\n",
    "db.load_button_quant_data_from_file(root / 'd2_TitrationSeries_Analysis.csv.bz2')\n",
    "#from htbam_analysis.htbam_db_api import LocalHtbamDBAPI\n",
    "\n",
    "root = '../local_test_data/'\n",
    "db_conn = LocalHtbamDBAPI(standard_curve_data_path= root + 'd1_2_StandardSeries_Analysis.csv.bz2', standard_name=\"NADPH std curve\", standard_type=\"NADPH\", standard_units=\"uM\",\n",
    "                         kinetic_data_path= root+ 'd1_TitrationSeries_Analysis.csv', kinetic_name=\"ADP kinetics curve\", kinetic_type=\"ADP\", kinetic_units=\"uM\")\n",
    "\n",
    "### TODO: Still want the following data in the database:\n",
    "# date (and time?) collected\n",
    "# operator name\n",
    "# Add additional descriptors\n",
    "# substrate_name\n",
    "# setup(?) and device_num\n",
    "# width/height\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format of DB:\n",
    "Useful? Or remove?\n",
    "DB\n",
    "- **chamber_metadata**\n",
    "    - '1,1'\n",
    "        - 'id'                  'organism_ADK'\n",
    "        - 'radius_chamber'      35.0\n",
    "        - 'x_center_chamber'    31.0\n",
    "        - 'y_center_chamber'    43.0\n",
    "        - 'xslice'              '(6758, 6805)'\n",
    "        - 'yslice'              '(6704, 6804)'\n",
    "    - ...\n",
    "    - '32,56' ...\n",
    "- **runs**\n",
    "    - 'standard_0'\n",
    "        - 'name'            'NAPDH_std_curve'\n",
    "        - 'type'            'NAPDH'\n",
    "        - 'conc_unit'       'uM'\n",
    "        - 'assays':\n",
    "            - 0:\n",
    "                - 'conc'\n",
    "                - 'time_s'\n",
    "                - 'chambers'\n",
    "                    - '1,1'\n",
    "                    - ...\n",
    "                    - '32,56' ...\n",
    "            - ...\n",
    "            - 6: ...\n",
    "        - 'analyses':\n",
    "            - 'linear_regression':\n",
    "                - 'chambers':\n",
    "                    - '1,1':\n",
    "                        - slope:\n",
    "                        - intercept:\n",
    "                        - r_value:\n",
    "                        - p_value: \n",
    "                        - std_err:\n",
    "                    - ...\n",
    "                    - '32,56'...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Standards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each chamber, we've taken values at a set of concentrations. We need to perform a linear regression __for each chamber__ to relate the luminance of each chamber to its substrate concentration.\n",
    "\n",
    "In our hierarchical data structure, we will store this linear regression as an analysis under the standard curve experiment. It is stored under:\n",
    "\n",
    "```db_conn._json_dict['runs']['standard_0']['analyses']['linear_regression']```\n",
    "\n",
    "And it stores the data:\n",
    "```\n",
    "{'chambers':  {'1,1': \n",
    "                     {'intercept': ...,\n",
    "                      'p_value': ...,\n",
    "                      'r2': ...,\n",
    "                      'r_value': ...,\n",
    "                      'slope': ...,\n",
    "                      'std_err': ...,\n",
    "                     }\n",
    "               '1,2': {'intercept': ...}\n",
    "              }\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's automatigically generate the standard curve by doing a linear regression:\n",
    "kinetics.chip.analysis.new_analysis(db, 'standard_0', 'linear_regression', 'linear_regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.get('runs/standard_0/analyses/linear_regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check:\n",
    "Now, let's sanity check by plotting. We can use the ```plot_chip()``` function to show a chip where each chamber is colored by variable (like luminance). We can also make subplots on hover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kinetics.chip import visualization \n",
    "kinetics.chip.visualization.plot(db, \n",
    "                                 run_name=      'standard_0', \n",
    "                                 analysis_name= 'linear_regression', \n",
    "                                 plotting_var=  'r2', \n",
    "                                 title=         'Standard Curve', \n",
    "                                 hover_data=    ['conc', 'sum_chamber'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Fit initial rates from processed kinetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this next part, we'll be generating the predicted product concentration for each well, for each time, and for each substrate concentration. That's a 3D array.\n",
    "\n",
    "To do this, we divide our luminance value (in RFUs) by the slope of the chamber's standard curve (RFU/conc). Here, we ignore the standard curve intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chamber_coords, luminance_data, conc_data, time_data = db.get_run_data('kinetics_0')\n",
    "print('Luminance data shape:', luminance_data.shape) #(time x wells x assays)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each well contains time_series data. We have 32*56 wells (1792), and then N assays with different concentrations.\n",
    "So we have a np array with dimensions (time x wells x assays)\n",
    "For a standard, this will be (1, 1792, # concentrations)\n",
    "For a kinetics run, this will be (~20, 1792, # concentrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make temporary copy of data:\n",
    "chamber_dict = db.get(f'runs/standard_0/analyses/linear_regression/chambers/')\n",
    "chamber_dict = db._make_quantities_from_serialized_dict(chamber_dict)\n",
    "\n",
    "#concatenate all the slope quantities:\n",
    "slope_quantities = [chamber_dict[i]['slope'] for i in chamber_dict.keys()]\n",
    "# Assuming `slope_quantities` is the list of quantities\n",
    "slope_array = np.array([q.magnitude for q in slope_quantities]) * slope_quantities[0].units\n",
    "print('Slope quantities:', slope_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_concentration = luminance_data / slope_array[np.newaxis, :, np.newaxis]\n",
    "print('Product concentration shape:', product_concentration.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_quant_no_background = np.array([])\n",
    "button_quant_unit = None\n",
    "chamber_dict = db.get(f'button_quant/')\n",
    "chamber_dict = db._make_quantities_from_serialized_dict(chamber_dict)\n",
    "for chamber_coord in chamber_coords:\n",
    "    button_quant_no_background = np.append(button_quant_no_background, chamber_dict[chamber_coord]['summed_button_BGsub_Button_Quant'].magnitude)\n",
    "    if button_quant_unit is None:\n",
    "        button_quant_unit = chamber_dict[chamber_coord]['summed_button_BGsub_Button_Quant'].units\n",
    "button_quant_no_background = button_quant_no_background * button_quant_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what's the enzyme concentration in each well?\n",
    "enzyme_concentration = button_quant_no_background / EGFP_SLOPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enzyme_concentration.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we should probably be storing these in the DB under a standard_0 analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #make numpy array of all button_quants with[ subtracted backgrounds:\n",
    "# button_quant_no_background = [] #we will soon turn this into a numpy array\n",
    "# for chamber_idx in chamber_idxs:\n",
    "#     next_button_quant = db_conn._json_dict['button_quant'][chamber_idx]['summed_button_BGsub_Button_Quant']\n",
    "#     button_quant_no_background.append(next_button_quant)\n",
    "# button_quant_no_background = np.array(button_quant_no_background)\n",
    "\n",
    "# # use eGFP standard curve to convert between button quant and eGFP concentration\n",
    "# enzyme_concentration = button_quant_no_background / EGFP_SLOPE    #in units of EGFP_SLOPE_CONC_UNITS\n",
    "# print('Enzyme concentration shape:', enzyme_concentration.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Fit initial rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###TODO:\n",
    "# 1) ~~I think addings nans kills the line fitting. Fix at some point. (in line fitting code, so we can keep nans?)~~\n",
    "#    Fixed? Appears like it's working properly.\n",
    "# 2) We're using the time values for the first chamber for all chambers. \n",
    "#    In practice, they're sometimes off by 1 second, which should not affect results much. Perhaps change in the future.\n",
    "# 3) Kinetics fails without substrate_conc, even though it says it's optional. Also prints an ugly array which we should disable.\n",
    "\n",
    "from kinetics import get_initial_slopes_quantities\n",
    "\n",
    "#make an array of initial slopes for each chamber: should be (#chambers , #concentrations) = (1792 x 11)\n",
    "initial_slopes = None\n",
    "initial_slopes_R2 = None\n",
    "for i, chamber_coord in enumerate(chamber_coords):\n",
    "\n",
    "    #use the kinetics package to calculate the slopes for this chamber at each substrate concentration.\n",
    "    current_chamber_slopes, current_chamber_R2 = kinetics.get_initial_slopes_quantities(time_data[:,0], product_concentration[:,i,:].T, substrate_concs=conc_data)\n",
    "\n",
    "    #add a dimension at the end:\n",
    "    current_chamber_slopes = np.expand_dims(current_chamber_slopes, axis=0)\n",
    "    current_chamber_R2 = np.expand_dims(current_chamber_R2, axis=0)\n",
    "    \n",
    "    #add to our complete array:\n",
    "    if initial_slopes is None:\n",
    "        initial_slopes = current_chamber_slopes\n",
    "        initial_slopes_R2 = current_chamber_R2\n",
    "    else:\n",
    "        initial_slopes = np.concatenate([initial_slopes, current_chamber_slopes], axis=0)\n",
    "        initial_slopes_R2 = np.concatenate([initial_slopes_R2, current_chamber_R2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot as before:\n",
    "#plotting variable: We'll plot by luminance. We need a dictionary mapping chamber id (e.g. '1,1') to the value to be plotted (e.g. slope)\n",
    "initial_rates_to_plot = {chamber_coords[i]: np.nanmax(initial_slopes[i,:]) for i in range(len(chamber_coords))}\n",
    "#Plot the slopes of each chamber with 0 inhibitor: (the 0th value, since we sort concentration low to high)\n",
    "zero_inhibitor_rates_to_plot = {chamber_idxs[i]: initial_slopes[i,0] for i in range(len(chamber_idxs))}\n",
    "\n",
    "#chamber_names: Same as before.\n",
    "\n",
    "#plotting function: We'll generate a subplot for each chamber, showing the raw data and the linear regression line.\n",
    "# to do this, we make a function that takes in the chamber_id and the axis object, and returns the axis object after plotting. Do NOT plot.show() in this function.\n",
    "def plot_chamber_initial_rates(chamber_id, ax):\n",
    "    #N.B. Every so often, slope and line colors don't match up. Not sure why.\n",
    "    #parameters: what amount of total time to plot? First 20%?\n",
    "    time_to_plot = 0.2\n",
    "    \n",
    "    #convert from 'x,y' to integer index in the array:\n",
    "    data_index = list(chamber_coords).index(chamber_id)\n",
    "\n",
    "    x_data = time_data[:,0]\n",
    "    y_data = product_concentration[:,data_index,:].T\n",
    "    \n",
    "    #plot only first X% of time:\n",
    "    max_time = np.nanmax(x_data)\n",
    "    time_to_plot = max_time*time_to_plot\n",
    "    time_idxs_to_plot = x_data < time_to_plot\n",
    "    x_data = x_data[time_idxs_to_plot]\n",
    "    y_data = y_data[:, time_idxs_to_plot]\n",
    "    \n",
    "    #get slope from the analysis:\n",
    "    current_chamber_slopes = initial_slopes[data_index,:]\n",
    "    #calculate y-intercept by making sure it intersects first point:\n",
    "    current_chamber_intercepts = y_data[:,0] - current_chamber_slopes*x_data[0] #note: not true y-intercept from linear regression\n",
    "    \n",
    "    for i in range(y_data.shape[0]): #over each concentration:\n",
    "        ax.scatter(x_data, y_data[i,:])\n",
    "        m = current_chamber_slopes[i]\n",
    "        b = current_chamber_intercepts[i]\n",
    "        if not (np.isnan(m) or np.isnan(b)):\n",
    "            #return False, no_update, no_update\n",
    "            ax.plot(x_data, m*np.array(x_data) + b)\n",
    "    return ax\n",
    "\n",
    "\n",
    "### PLOT THE CHIP: now, we plot\n",
    "# kinetics.chip.visualization.plot(db, \n",
    "#                                  run_name=      'standard_0', \n",
    "#                                  analysis_name= 'linear_regression', \n",
    "#                                  plotting_var=  'r2', \n",
    "#                                  title=         'Standard Curve', \n",
    "#                                  hover_data=    ['conc', 'sum_chamber'])\n",
    "#chamber_names: We'll provide the name of the sample in each chamber as well, in the same way:\n",
    "chamber_names_dict = {chamber_idx: subdict['id'] for chamber_idx, subdict in db.get('chamber_metadata').items()}\n",
    "kinetics.chip.visualization._plot_chip(initial_rates_to_plot, chamber_names_dict, graphing_function=plot_chamber_initial_rates, title='Kinetics: Initial Rates (Max)')\n",
    "plot_chip(zero_inhibitor_rates_to_plot, chamber_names_dict, graphing_function=plot_chamber_initial_rates, title='Kinetics: Initial Rates (Zero Inhibitor)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 8. Filter initial rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filters:\n",
    "We will filter by masking our product_concentration array with NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter threshholds ###\n",
    "\n",
    "#standard curve r^2 threshhold:\n",
    "r2_threshold = 0.98\n",
    "\n",
    "#enzyme expression threshhold:\n",
    "expression_threshhold = 1.0\n",
    "expression_threshhold_units = 'nM'\n",
    "\n",
    "#initial rate fit R^2 threshhold:\n",
    "intitial_rate_R2_threshhold = 0.8\n",
    "\n",
    "#slope threshold for zero-inhibitor:\n",
    "zero_inhibitor_slope_threshhold = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make filters ###\n",
    "\n",
    "# STANDARD CURVE FILTER #\n",
    "# overwrite all chambers (rows) with r^2 values below the threshold with NaNs:\n",
    "filter_r2 = np.ones_like(initial_slopes)\n",
    "r2_values = np.array([db_conn._json_dict['runs']['standard_0']['analyses']['linear_regression']['chambers'][chamber_idx]['r2'] for chamber_idx in chamber_idxs])\n",
    "_count = 0\n",
    "for i, chamber_idx in enumerate(chamber_idxs):\n",
    "    if r2_values[i] < r2_threshold:\n",
    "        _count +=1\n",
    "        filter_r2[i, :] = np.nan\n",
    "print('Pearson r^2 filter: {}/{} chambers pass'.format(len(chamber_idxs)-_count, len(chamber_idxs)))\n",
    "\n",
    "# ENZYME EXPRESSION FILTER #\n",
    "# overwrite all chambers (rows) with enzyme expression below the threshold with NaNs:\n",
    "#Double check the expression units match the EGFP units:\n",
    "assert expression_threshhold_units == EGFP_SLOPE_CONC_UNITS, 'Error, enzyme expression and EGFP standard curve units do not match!'\n",
    "filter_enzyme_expression = np.ones_like(initial_slopes)\n",
    "_count = 0\n",
    "for i, chamber_idx in enumerate(chamber_idxs):\n",
    "    if enzyme_concentration[i] < expression_threshhold:\n",
    "        _count +=1\n",
    "        filter_enzyme_expression[i,:] = np.nan\n",
    "print('Enzyme expression filter: {}/{} chambers pass'.format(len(chamber_idxs)-_count, len(chamber_idxs)))\n",
    "\n",
    "# ZERO-INHIBITOR SLOPE FILTER #\n",
    "# overwrite all chambers (rows) where the initial slope is below the threshhold with NaNs:\n",
    "filter_zero_inhibitor_rate = np.ones_like(initial_slopes)\n",
    "_count = 0\n",
    "for i, chamber_idx in enumerate(chamber_idxs):\n",
    "    if initial_slopes[i,0] < zero_inhibitor_slope_threshhold:\n",
    "        _count +=1\n",
    "        filter_zero_inhibitor_rate[i,:] = np.nan\n",
    "print('0 Inhibitor rate filter: {}/{} chambers pass'.format(len(chamber_idxs)-_count, len(chamber_idxs)))\n",
    "\n",
    "# INITIAL RATE FIT FILTER #\n",
    "# overwrite just the assays per chamber (single values) with initial rate fit R^2 values below the threshold with NaNs:\n",
    "filter_initial_rate_R2 = np.ones_like(initial_slopes)\n",
    "_count = 0\n",
    "for i, chamber_idx in enumerate(chamber_idxs):\n",
    "    _chamber_count = 0\n",
    "    for j in range(len(conc_data)):\n",
    "        if initial_slopes_R2[i,j] < intitial_rate_R2_threshhold:\n",
    "            _chamber_count +=1\n",
    "            filter_initial_rate_R2[i,j] = np.nan\n",
    "    if len(conc_data) - _chamber_count < 10:\n",
    "        _count +=1\n",
    "print('Initial Rate R^2 filter: {}/{} chambers pass with 10 or more slopes.'.format(len(chamber_idxs)-_count, len(chamber_idxs)))\n",
    "\n",
    "# POSITIVE INITIAL SLOPE FILTER #\n",
    "# overwrite just the assays per chamber (single values) with initial slopes below zero with NaNs:\n",
    "filter_positive_initial_slope = np.ones_like(initial_slopes)\n",
    "_count = 0\n",
    "for i, chamber_idx in enumerate(chamber_idxs):\n",
    "    _chamber_count = 0\n",
    "    for j in range(len(conc_data)):\n",
    "        if initial_slopes[i,j] < 0:\n",
    "            _chamber_count +=1\n",
    "            filter_positive_initial_slope[i,j] = np.nan\n",
    "    if len(conc_data) - _chamber_count < 10:\n",
    "        _count +=1\n",
    "print('Positive Initial Slope filter: {}/{} chambers pass with 10 or more slopes.'.format(len(chamber_idxs)-_count, len(chamber_idxs)))\n",
    "\n",
    "\n",
    "### manually flagged wells ###\n",
    "#TODO: implement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter data ###\n",
    "#apply filters:\n",
    "filters = [filter_r2, filter_enzyme_expression, filter_initial_rate_R2, filter_positive_initial_slope, filter_zero_inhibitor_rate]\n",
    "\n",
    "filtered_initial_slopes = deepcopy(initial_slopes)\n",
    "for filter in filters: filtered_initial_slopes *= filter\n",
    "\n",
    "#then, filter our enzyme concentration:\n",
    "enzyme_concentration_filtered = enzyme_concentration * filter_enzyme_expression[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chamber_idxs, luminance_data, conc_data, time_data\n",
    "\n",
    "#save filtered data to new analysis:\n",
    "if 'analyses' not in db_conn._json_dict['runs']['kinetics_0'].keys():\n",
    "    db_conn._json_dict['runs']['kinetics_0']['analyses'] = {}\n",
    "\n",
    "#initialize the dictionary\n",
    "db_conn._json_dict['runs']['kinetics_0']['analyses']['initial_slopes_filtered'] = {\n",
    "        'filters': ['filter_r2', 'filter_enzyme_expression', 'filter_initial_rate_R2', 'filter_positive_initial_slope'],\n",
    "        'filter_r2': r2_threshold,\n",
    "        'filter_enzyme_expression': expression_threshhold,\n",
    "        'filter_enzyme_expression_units': expression_threshhold_units,\n",
    "        'filter_initial_rate_R2': intitial_rate_R2_threshhold,\n",
    "        'filter_positive_initial_slope': True,\n",
    "        'assays': {}} \n",
    "\n",
    "for i in range(len(conc_data)):\n",
    "    db_conn._json_dict['runs']['kinetics_0']['analyses']['initial_slopes_filtered']['assays'][i] = {\n",
    "        'substrate_conc': conc_data[i],\n",
    "        'chambers': {}\n",
    "    }\n",
    "    for j, chamber_idx in enumerate(chamber_idxs):\n",
    "        db_conn._json_dict['runs']['kinetics_0']['analyses']['initial_slopes_filtered']['assays'][i]['chambers'][chamber_idx] = {\n",
    "            'slope': filtered_initial_slopes[j,i],\n",
    "            'r2': initial_slopes_R2[j,i]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###N.B.: May be some bug here, because some of the filtered-out chambers are still showing slopes.\n",
    "# I think they should have all nans...?\n",
    "\n",
    "#Let's plot as before:\n",
    "#plotting variable: We'll plot by luminance. We need a dictionary mapping chamber id (e.g. '1,1') to the value to be plotted (e.g. slope)\n",
    "filtered_initial_rates_to_plot = {chamber_idxs[i]: np.any(~np.isnan(filtered_initial_slopes[i,:])) for i in range(len(chamber_idxs))}\n",
    "\n",
    "#chamber_names: Same as before.\n",
    "\n",
    "#plotting function: We'll generate a subplot for each chamber, showing the raw data and the linear regression line.\n",
    "# to do this, we make a function that takes in the chamber_id and the axis object, and returns the axis object after plotting. Do NOT plot.show() in this function.\n",
    "def plot_chamber_filtered_initial_rates(chamber_id, ax):\n",
    "    #N.B. Every so often, slope and line colors don't match up. Not sure why.\n",
    "    #parameters: what amount of total time to plot? First 20%?\n",
    "    time_to_plot = 0.2\n",
    "    \n",
    "    #convert from 'x,y' to integer index in the array:\n",
    "    data_index = list(chamber_idxs).index(chamber_id)\n",
    "\n",
    "    x_data = time_data[:,0]\n",
    "    y_data = product_concentration[:,data_index,:].T\n",
    "    \n",
    "    #plot only first X% of time:\n",
    "    max_time = np.nanmax(x_data)\n",
    "    time_to_plot = max_time*time_to_plot\n",
    "    time_idxs_to_plot = x_data < time_to_plot\n",
    "    x_data = x_data[time_idxs_to_plot]\n",
    "    y_data = y_data[:, time_idxs_to_plot]\n",
    "    \n",
    "    #get slope from the analysis:\n",
    "    current_chamber_slopes = filtered_initial_slopes[data_index,:]\n",
    "    #calculate y-intercept by making sure it intersects first point:\n",
    "    current_chamber_intercepts = y_data[:,0] - current_chamber_slopes*x_data[0] #note: not true y-intercept from linear regression\n",
    "    \n",
    "    for i in range(y_data.shape[0]): #over each concentration:\n",
    "        ax.scatter(x_data, y_data[i,:])\n",
    "        m = current_chamber_slopes[i]\n",
    "        b = current_chamber_intercepts[i]\n",
    "        if not (np.isnan(m) or np.isnan(b)):\n",
    "            #return False, no_update, no_update\n",
    "            ax.plot(x_data, m*np.array(x_data) + b)\n",
    "    return ax\n",
    "\n",
    "\n",
    "### PLOT THE CHIP: now, we plot\n",
    "plot_chip(filtered_initial_rates_to_plot, chamber_names_dict, graphing_function=plot_chamber_filtered_initial_rates, title='Kinetics: Filtered Initial Rates (Max)')\n",
    "print('{}/1792 wells pass our filters.'.format( np.sum([x for x in filtered_initial_rates_to_plot.values()]) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Fit Inhibition Constant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "substrate_conc_unit = db_conn._json_dict['runs']['kinetics_0']['conc_unit']\n",
    "if  substrate_conc_unit != EGFP_SLOPE_CONC_UNITS: print('Substrate concentration units do not match EGFP standard curve units! \\n{} != {}'.format(substrate_conc_unit, EGFP_SLOPE_CONC_UNITS))\n",
    "\n",
    "unit_converstion = 0.001 #convert FROM eGFP units TO substrate units (in this case, nM to uM)\n",
    "enzyme_concentration_converted_units = enzyme_concentration_filtered * unit_converstion\n",
    "\n",
    "#Double check!\n",
    "print('Conversion:')\n",
    "print('{} {} = {} {}  ?'.format(enzyme_concentration[0], EGFP_SLOPE_CONC_UNITS, enzyme_concentration_converted_units[0], substrate_conc_unit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, we calculate the Michaelis-Menten parameters for each chamber.\n",
    "\n",
    "K_i_array = np.array([])\n",
    "K_i_error_array = np.array([])\n",
    "\n",
    "for i in range(len(chamber_idxs)):\n",
    "    current_slopes = filtered_initial_slopes[i, :]\n",
    "\n",
    "    if np.all(np.isnan(current_slopes)):\n",
    "        print('Chamber {} has no slopes!'.format(chamber_idxs[i]))\n",
    "        K_i_array = np.append(K_i_array, np.nan)\n",
    "        K_i_error_array = np.append(K_i_error_array, np.nan)\n",
    "        continue\n",
    "\n",
    "    #get indices of non-nan values:\n",
    "    non_nan_idxs = np.where(~np.isnan(current_slopes))[0]\n",
    "    \n",
    "    current_slopes = current_slopes[non_nan_idxs]\n",
    "    current_concs = conc_data[non_nan_idxs]\n",
    "\n",
    "    if len(current_slopes) < 3:\n",
    "        print('Chamber {} has fewer than 3 slopes!'.format(chamber_idxs[i]))\n",
    "        K_i_array = np.append(K_i_array, np.nan)\n",
    "        K_i_error_array = np.append(K_i_error_array, np.nan)\n",
    "        continue\n",
    "    \n",
    "    #kinetics.fit_and_plot_micheaelis_menten(current_slopes, current_slopes, current_concs, enzyme_concentration_converted_units[i], 'uM', 'MM for first chamber!')\n",
    "    K_i, std_err = kinetics.fit_inhibition_constant(current_slopes, current_slopes, current_concs, enzyme_concentration_converted_units[i], 'uM', 'MM for first chamber!')\n",
    "    K_i_array = np.append(K_i_array, K_i)\n",
    "    K_i_error_array = np.append(K_i_error_array, std_err[0])\n",
    "\n",
    "#in case we're not using Cheng-Prusoff:\n",
    "K_i_array_corrected = K_i_array\n",
    "K_i_error_array_corrected = K_i_error_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: Correct with Cheng-Prusoff, using $K_M$.\n",
    "To use this, the $K_M$ input CSV ('sample_KMs.csv') must have the following columns:\n",
    "| Sample Name | K_M (uM) |\n",
    "|-------------|----------|\n",
    "| (string)  |  float | \n",
    "| $\\vdots$  |  $\\vdots$ | \n",
    "\n",
    "\n",
    "Additionally, please input the substrate_concentration for this assay (previously, we have been dealing with the inhibitor_concentration for fitting.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "assay_substrate_conc = 0 # uM\n",
    "\n",
    "sample_KM_dict = {}\n",
    "#get sample_names and KMs from csv:\n",
    "with open('sample_KMs.csv', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        sample_KM_dict[row['Sample Name']] = float(row['K_M (uM)'])\n",
    "\n",
    "K_M_array = np.array([])\n",
    "for chamber_idx in chamber_idxs:\n",
    "    #get the sample name for this chamber:\n",
    "    sample_name = chamber_names_dict[chamber_idx]\n",
    "    if sample_name not in sample_KM_dict.keys():\n",
    "        print('Sample {} not found in sample_KMs.csv!'.format(sample_name))\n",
    "        K_M_array = np.append(K_M_array, np.nan)\n",
    "        continue\n",
    "    current_K_M = sample_KM_dict[sample_name]\n",
    "    K_M_array = np.append(K_M_array, current_K_M)\n",
    "\n",
    "#correct each K_i using cheng-prusoff:\n",
    "K_i_array_corrected = kinetics.apply_cheng_prusoff(K_i_array, K_M_array, assay_substrate_conc, conc_units='uM')\n",
    "K_i_error_array_corrected = kinetics.apply_cheng_prusoff(K_i_error_array, K_M_array, assay_substrate_conc, conc_units='uM')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chamber_idxs, luminance_data, conc_data, time_data\n",
    "\n",
    "#save filtered data to new analysis:\n",
    "if 'analyses' not in db_conn._json_dict['runs']['kinetics_0'].keys():\n",
    "    db_conn._json_dict['runs']['kinetics_0']['analyses'] = {}\n",
    "\n",
    "#initialize the dictionary\n",
    "db_conn._json_dict['runs']['kinetics_0']['analyses']['K_i_raw'] = {\n",
    "        'chambers': {}} \n",
    "\n",
    "#TODO: currently, we're actually saving K_i/E. This is reflected in output but not in our internal names\n",
    "# this will be fixed in the next refactor.\n",
    "for i, chamber_idx in enumerate(chamber_idxs):\n",
    "    db_conn._json_dict['runs']['kinetics_0']['analyses']['K_i_raw']['chambers'][chamber_idx] = {\n",
    "        'K_i': K_i_array_corrected[i],\n",
    "        'K_i_error': K_i_error_array_corrected[i],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get chamber ids from metadata:\n",
    "chamber_name_to_idx = {}\n",
    "for chamber_idx, subdict in db_conn._json_dict['chamber_metadata'].items():\n",
    "    name = subdict['id']\n",
    "    if name not in chamber_name_to_idx.keys():\n",
    "        chamber_name_to_idx[name] = [chamber_idx]\n",
    "    else:\n",
    "        chamber_name_to_idx[name].append(chamber_idx)\n",
    "\n",
    "#get average number of replicates:\n",
    "n_replicates = np.mean([len(x) for x in chamber_name_to_idx.values()])\n",
    "print('Average number of replicates per sample: {}'.format(np.round(n_replicates, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score_threshhold_MM = 1.5\n",
    "z_score_threshhold_expression = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get average k_cat, k_M, and v_max for each sample:\n",
    "sample_names = np.array([])\n",
    "sample_K_i = np.array([])\n",
    "sample_K_i_error = np.array([])\n",
    "sample_K_i_replicates = []\n",
    "\n",
    "#Get z-scores for each well (used to filter in the next step!)\n",
    "K_i_zscores = np.array([])\n",
    "enzyme_concentration_zscores = np.array([])\n",
    "\n",
    "#For each sample, \n",
    "for name, ids in chamber_name_to_idx.items():\n",
    "\n",
    "    ### GATHER MM PARAMETERS OF REPLICATES FOR EACH SAMPLE: ###\n",
    "    #get indices of idxs in chamber_idxs:\n",
    "    idxs = [list(chamber_idxs).index(x) for x in ids]\n",
    "\n",
    "    #get values for those indices:\n",
    "    K_i = K_i_array_corrected[idxs]\n",
    "    #keep track of which wells we exclude later:\n",
    "    K_i_replicates = np.array(ids)\n",
    "\n",
    "    #if any of these is all nans, just continue to avoid errors:\n",
    "    if np.all(np.isnan(K_i)):\n",
    "        print('No values from sample {}, all pre-filtered.'.format(name))\n",
    "        continue\n",
    "\n",
    "    ### FILTER OUT OUTLIERS: ###\n",
    "    #calculate z-score for each value:\n",
    "    K_i_zscore = (K_i - np.nanmean(K_i))/np.nanstd(K_i)\n",
    "\n",
    "    #also, get z-score of enzyme expression for each well:\n",
    "    enzyme_concentration_zscore = (enzyme_concentration_converted_units[idxs] - np.nanmean(enzyme_concentration_converted_units[idxs]))/np.nanstd(enzyme_concentration_converted_units[idxs]) #in units of 'substrate_conc_unit' \n",
    "\n",
    "    #First, for enzyme expression outliers, set the value to NaN to be filtered in the final step:\n",
    "    K_i[np.abs(enzyme_concentration_zscore) > z_score_threshhold_expression] = np.nan\n",
    "\n",
    "    #filter out values with z-score > threshhold:\n",
    "    K_i = K_i[np.abs(K_i_zscore) < z_score_threshhold_MM]\n",
    "\n",
    "    #do the same for the replicates ids:\n",
    "    K_i_replicates = K_i_replicates[np.abs(K_i_zscore) < z_score_threshhold_MM]\n",
    "\n",
    "    #remove nan values from all (nan values are due to both no experimental data, and z-score filtering)\n",
    "    K_i_replicates = K_i_replicates[~np.isnan(K_i)]\n",
    "    K_i = K_i[~np.isnan(K_i)]\n",
    "\n",
    "    if len(K_i) < 3:\n",
    "        print('Not enough replicates for sample {}. Skipping.'.format(name))\n",
    "        continue\n",
    "    \n",
    "    #get average values:\n",
    "    sample_names = np.append(sample_names, name)\n",
    "    sample_K_i = np.append(sample_K_i, np.mean(K_i))\n",
    "    sample_K_i_error = np.append(sample_K_i_error,np.std(K_i))\n",
    "    \n",
    "    #keep track of replicates:\n",
    "    sample_K_i_replicates.append(K_i_replicates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save filtered data to new analysis:\n",
    "if 'analyses' not in db_conn._json_dict['runs']['kinetics_0'].keys():\n",
    "    db_conn._json_dict['runs']['kinetics_0']['analyses'] = {}\n",
    "\n",
    "#initialize the dictionary\n",
    "db_conn._json_dict['runs']['kinetics_0']['analyses']['K_i_filtered'] = {\n",
    "        'samples': {}} \n",
    "\n",
    "for i, sample_name in enumerate(sample_names):\n",
    "    db_conn._json_dict['runs']['kinetics_0']['analyses']['K_i_filtered']['samples'][sample_name] = {\n",
    "        'K_i': sample_K_i[i],\n",
    "        'K_i_error': sample_K_i_error[i],\n",
    "        'K_i_replicates': sample_K_i_replicates[i],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize:\n",
    "#plotting variable: We'll plot by K_M. We need a dictionary mapping chamber id (e.g. '1,1') to the value to be plotted\n",
    "#first, fill it with NaNs as a placeholder:\n",
    "K_i_to_plot = {chamber_idx: np.nan for chamber_idx in chamber_idxs}\n",
    "#then, fill in the values we have:\n",
    "for i in range(len(sample_names)):\n",
    "    for chamber_idx in chamber_name_to_idx[sample_names[i]]:\n",
    "        K_i_to_plot[chamber_idx] = sample_K_i[i]\n",
    "\n",
    "#chamber_names: We'll provide the name of the sample in each chamber as well, in the same way:\n",
    "chamber_names_dict = {chamber_idx: subdict['id'] for chamber_idx, subdict in db_conn._json_dict['chamber_metadata'].items()}\n",
    "\n",
    "\n",
    "#plotting function: We'll generate an MM subplot for each chamber.\n",
    "def plot_chamber_K_i(chamber_id, ax):\n",
    "    def inhibition_model(x, Ki, v_0):\n",
    "        return v_0 / (1 + (x / Ki))\n",
    "    \n",
    "    #find the name of the chamber:\n",
    "    chamber_name = chamber_names_dict[chamber_id]\n",
    "    #first, find all chambers with this name:\n",
    "    #if there's no data, just skip!\n",
    "    if chamber_name not in db_conn._json_dict['runs']['kinetics_0']['analyses']['K_i_filtered']['samples']:\n",
    "        return ax\n",
    "    chamber_id_list = db_conn._json_dict['runs']['kinetics_0']['analyses']['K_i_filtered']['samples'][chamber_name]['K_i_replicates']\n",
    "\n",
    "    #convert to array indices:\n",
    "    chamber_id_list = [list(chamber_idxs).index(x) for x in chamber_id_list]\n",
    "\n",
    "    #get the initial rates for each chamber:\n",
    "    initial_slopes = filtered_initial_slopes[chamber_id_list,:]\n",
    "    #divide by enzyme concentration:\n",
    "    initial_slopes_on_E = initial_slopes / enzyme_concentration_converted_units[chamber_id_list, np.newaxis]\n",
    "    #get average\n",
    "    initial_slopes_on_E_avg = np.nanmean(initial_slopes_on_E, axis=0)\n",
    "    #get error bars\n",
    "    initial_slopes_on_E_std = np.nanstd(initial_slopes_on_E, axis=0)\n",
    "\n",
    "    #get the substrate concentrations that match with each initial rate:\n",
    "    substrate_concs = conc_data\n",
    "\n",
    "    x_data = substrate_concs\n",
    "    y_data = initial_slopes_on_E_avg\n",
    "\n",
    "    data_index = list(chamber_idxs).index(chamber_id)\n",
    "    current_chamber_slopes = filtered_initial_slopes[data_index,:]\n",
    "    current_chamber_slopes_on_E = current_chamber_slopes / enzyme_concentration_converted_units[data_index]\n",
    "    \n",
    "    #make x,y labels:\n",
    "    ax.set_xlabel('[I] ({})'.format(substrate_conc_unit))\n",
    "    ax.set_ylabel('Ki/[E]')\n",
    "\n",
    "    #plot with error bars:\n",
    "    ax.errorbar(x_data, y_data, yerr=initial_slopes_on_E_std, fmt='o', label=\"all replicates\")\n",
    "\n",
    "    #get enzyme concentration:\n",
    "    enzyme_conc = np.nanmean(enzyme_concentration_converted_units[chamber_id_list])\n",
    "\n",
    "    #plot the fit:\n",
    "    #get the Ki and v_0 from the database:\n",
    "    Ki = K_i_to_plot[chamber_id] * enzyme_conc\n",
    "    v_0 = y_data[0]\n",
    "    \n",
    "    #plot dotted line\n",
    "    ax.plot(x_data, inhibition_model(x_data, Ki, v_0), '--', linewidth=2,  label=\"MM fit\")\n",
    "\n",
    "    #plot over everything else:\n",
    "    ax.scatter(x_data, current_chamber_slopes_on_E, marker='o', color='red', s=50, zorder=10,  label=\"current chamber\")\n",
    "    \n",
    "    ax.legend()\n",
    "    \n",
    "    return ax\n",
    "\n",
    "### PLOT THE CHIP: now, we plot\n",
    "plot_chip(K_i_to_plot, chamber_names_dict, graphing_function=plot_chamber_K_i, title='Filtered Ki')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export to CSV in format people like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary CSV, showing data for each SAMPLE:\n",
    "output_csv_name = 'inhibition_summary_2'\n",
    "\n",
    "import csv\n",
    "with open(output_csv_name+'_short.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    #write header:\n",
    "    writer.writerow(['id', \n",
    "                     'substrate_name', \n",
    "                     'assay_type', \n",
    "                     'replicates', \n",
    "                     'Ki_mean_filtered, '+substrate_conc_unit,\n",
    "                     'Ki_mean_filtered/[E]', \n",
    "                     'Ki_stdev_filtered/[E]', \n",
    "                     'enzyme, '+substrate_conc_unit])\n",
    "    #write data:\n",
    "    for i, sample_name in enumerate(sample_names):\n",
    "        #get the chamber indices for this sample:\n",
    "        chamber_indices = np.where(np.isin(chamber_idxs, chamber_name_to_idx[sample_name]))[0]\n",
    "        #get average enzyme conc:\n",
    "        enzyme_conc = np.nanmean(enzyme_concentration_converted_units[chamber_indices])\n",
    "        row = [sample_name,\n",
    "               sample_name,\n",
    "               db_conn._json_dict['runs']['kinetics_0']['type'], \n",
    "               len(sample_K_i_replicates[i]), \n",
    "               sample_K_i[i]*enzyme_conc,\n",
    "               sample_K_i[i], \n",
    "               sample_K_i_error[i], \n",
    "               enzyme_conc,\n",
    "               ]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full CSV, showing data for each CHAMBER:\n",
    "import csv\n",
    "output_csv_name = 'inhibition_2'\n",
    "\n",
    "with open(output_csv_name+'.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    #write header:\n",
    "    writer.writerow(['id', \n",
    "                     'x,y',\n",
    "                     'substrate_name', \n",
    "                     'assay_type', \n",
    "                     'replicates', \n",
    "                     'Ki, '+substrate_conc_unit,\n",
    "                     'Ki/[E]', \n",
    "                     'Ki_mean_filtered/[E]', \n",
    "                     'Ki_stdev_filtered/[E]', \n",
    "                     'enzyme, '+substrate_conc_unit,])\n",
    "    #write data for each chamber:\n",
    "    for i, chamber_idx in enumerate(chamber_idxs):\n",
    "        sample_name = chamber_names_dict[chamber_idx]\n",
    "        #get index in sample_names:\n",
    "        if sample_name in sample_names:\n",
    "            sample_idx = list(sample_names).index(sample_name)\n",
    "            row = [chamber_names_dict[chamber_idx], #id\n",
    "                    chamber_idx, #x,y\n",
    "                    sample_name, #substrate_name\n",
    "                    db_conn._json_dict['runs']['kinetics_0']['type'], #assay_type\n",
    "                    len(sample_K_i_replicates[sample_idx]), #replicates\n",
    "                    db_conn._json_dict['runs']['kinetics_0']['analyses']['K_i_raw']['chambers'][chamber_idx]['K_i']*enzyme_concentration_converted_units[i], #ki\n",
    "                    db_conn._json_dict['runs']['kinetics_0']['analyses']['K_i_raw']['chambers'][chamber_idx]['K_i'], #ki/E\n",
    "                    sample_K_i[sample_idx], #ki_mean_filtered/E\n",
    "                    sample_K_i_error[sample_idx], #ki_stdev_filtered/E\n",
    "                    enzyme_concentration_converted_units[i], #enzyme\n",
    "                    ]\n",
    "        else:\n",
    "            row = [chamber_names_dict[chamber_idx], #id\n",
    "                    chamber_idx, #x,y\n",
    "                    sample_name, #substrate_name\n",
    "                    db_conn._json_dict['runs']['kinetics_0']['type'], #assay_type\n",
    "                    'NaN', #replicates\n",
    "                    db_conn._json_dict['runs']['kinetics_0']['analyses']['K_i_raw']['chambers'][chamber_idx]['K_i']*enzyme_concentration_converted_units[i], #kcat\n",
    "                    db_conn._json_dict['runs']['kinetics_0']['analyses']['K_i_raw']['chambers'][chamber_idx]['K_i'], #kcat\n",
    "                    'NaN', #K_i_mean_filtered\n",
    "                    'NaN', #K_i_stdev_filtered\n",
    "                    enzyme_concentration_converted_units[i], #enzyme\n",
    "            ]\n",
    "        \n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Full output, so each chamber can be plotted individually:\n",
    "#rows for each chamber (by chamber_coord)\n",
    "#column for each assay concentration\n",
    "#values are slopes\n",
    "\n",
    "headers = ['chamber_coord']\n",
    "headers += [f\"assay {i} (uM): \" for i in range(len(conc_data))]\n",
    "headers_2 = ['']\n",
    "headers_2 += [conc for conc in conc_data]\n",
    "\n",
    "with open(output_csv_name+'_for_plotting.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    #write header:\n",
    "    writer.writerow(headers)\n",
    "    writer.writerow(headers_2)\n",
    "    #write data:\n",
    "    for i, chamber_idx in enumerate(chamber_idxs):\n",
    "        row = [chamber_idx]\n",
    "        row += list(filtered_initial_slopes[i,:])\n",
    "        writer.writerow(row)\n",
    "\n",
    "#units are uM/s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
