{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing Template: On-Chip Binding\n",
    "___\n",
    "Duncan Muir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from htbam_analysis.processing import chip\n",
    "from htbam_analysis.processing import experiment as exp\n",
    "from htbam_analysis.processing import chipcollections as collections\n",
    "from pathlib import Path \n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Establish experiment and pinlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/Volumes/DuncanSSD/20231212_new_binding_code/'\n",
    "description = 'adpr_binding_mac1'\n",
    "operator = 'DFM'\n",
    "setup_num = 's1'\n",
    "device_num = 'd1'\n",
    "device_dimensions = (32, 56)\n",
    "e = exp.Experiment(description, root, operator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Exposure and Channel Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_quant_channel = '2'\n",
    "button_quant_exposure = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mock a Pinlist for Flow-On Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinlist = e.read_pinlist(\"/Users/duncanmuir/Downloads/20230426_mac1_p1_p2_print_pinlist.csv\")\n",
    "pinlist.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add devices and corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top left, top right, bottom left, bottom right\n",
    "d1_corners = ((396, 398),(6665,373),(424,6778),(6689,6749)) \n",
    "\n",
    "#Do this in imageJ, put your cursor over the reaction chambers and copy over\n",
    "d1 = exp.Device(setup_num, device_num, device_dimensions, pinlist, d1_corners)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-standard chamber-finding parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chip.Stamp.circlePara1Index = 30\n",
    "#chip.Stamp.circlePara2Index = 15\n",
    "\n",
    "print('Old Chamber Radius: {} pixels'.format(chip.Stamp.chamberrad))\n",
    "chip.Stamp.chamberrad = 32#33 in 2x2\n",
    "print('New Chamber Radius: {} pixels'.format(chip.Stamp.chamberrad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Execute button analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantify egfp fluorescence on buttons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stitched image path\n",
    "button_quant_path = \"/Volumes/DuncanSSD/20231212_new_binding_code/button_quant/20231205-162503-d1_button_quant_2x2_sensitivity_4x/2/StitchedImages/BGSubtracted_StitchedImg_5_2_0.tif\"\n",
    "\n",
    "# Prepare ChipQuant object\n",
    "d1_GFPQuant = collections.ChipQuant(d1, 'ButtonReference')\n",
    "\n",
    "# Load image into memory\n",
    "d1_GFPQuant.load_file(button_quant_path, button_quant_channel, button_quant_exposure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find buttons, extract intensity attributes\n",
    "d1_GFPQuant.process()\n",
    "\n",
    "# Summarize attributes as a pandas dataframe\n",
    "quant_report1 = d1_GFPQuant.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Summary/Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_report1.to_csv(f'{root}/data_analysis/button_quant_summary.csv', index=True)\n",
    "\n",
    "d1_GFPQuant.save_summary_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code is having a hard time finding chambers in the standard curve (perhaps because it was resized?), so using this image as a reference\n",
    "\n",
    "d1_ChamberRef = collections.ChipQuant(d1, 'Chamber_Ref')\n",
    "d1_ChamberRef.load_file(button_quant_path, '2', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_ChamberRef.process(mapped_features = 'chamber', coerce_center = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Binding Assay\n",
    "\n",
    "Note: This is only applicable if you ran a binding experiment (obviously).\n",
    "\n",
    "There are three images taken for each concentration of prey: \n",
    "1. A pre-wash measurement of the bait.\n",
    "2. A post-wash measurement of the bait.\n",
    "3. A post-wash measurement of the prey.\n",
    "\n",
    "I process these images by first re-formatting the directory outputteed by the binding experiment into a format identical to that of a kinetics experiment. I've included some code for doing this in the cell below. Keep in mind this may require some tweaks depending on how your files or directories are named. For instance, the `get_handle()` and `concen_from_handle()` functions used to extract experiment data from filenames will almost certainly need to be tailored for your specific experiment.\n",
    "\n",
    "This is a hacky solution that will probably work alright until a newer version of the processing code is published. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-format the Binding Experiment Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create necessary directories, copy files, and rename files programatically\n",
    "\n",
    "import os \n",
    "import shutil \n",
    "import numpy as np\n",
    "\n",
    "binding_path = '/Volumes/DuncanSSD/20231212_new_binding_code/adpr_binding/'\n",
    "bait_channel, bait_exposure = '2', '5'\n",
    "prey_channel, prey_exposure = '4', '1'\n",
    "\n",
    "pre_wash_bait_dir = os.path.join(binding_path, 'pre_wash_bait')\n",
    "post_wash_bait_dir = os.path.join(binding_path, 'post_wash_bait')\n",
    "post_wash_prey_dir = os.path.join(binding_path, 'post_wash_prey')\n",
    "\n",
    "def get_handle(filename: str):\n",
    "\n",
    "    substring = filename.split('-')[-1]\n",
    "    substring = substring.split('_P')[0]\n",
    "    substring = substring.split('d1')[-1]\n",
    "    \n",
    "    return substring[1:]\n",
    "\n",
    "def concen_from_handle(handle: str, prey_name: str):\n",
    "\n",
    "    concen_string = handle.split(prey_name)[0][0:-1]\n",
    "    concen_string = concen_string.replace('_', '.')\n",
    "\n",
    "    return float(concen_string)\n",
    "\n",
    "source_dirs = os.listdir(binding_path)\n",
    "source_dirs.sort()\n",
    "#source_dirs = source_dirs[0:-1]\n",
    "file_handles = [get_handle(dir) for dir in source_dirs]\n",
    "concens = [concen_from_handle(handle, 'ADPR') for handle in file_handles]\n",
    "\n",
    "target_dirs = np.array([''] * len(file_handles), dtype='<U80')\n",
    "target_dirs[0::3] = pre_wash_bait_dir\n",
    "target_dirs[1::3] = post_wash_bait_dir\n",
    "target_dirs[2::3] = post_wash_prey_dir\n",
    "\n",
    "exposures = np.array([''] * len(file_handles), dtype='<U3')\n",
    "exposures[0::3] = bait_exposure\n",
    "exposures[1::3] = bait_exposure\n",
    "exposures[2::3] = prey_exposure\n",
    "\n",
    "channels = np.array([''] * len(file_handles), dtype='<U3')\n",
    "channels[0::3] = bait_channel\n",
    "channels[1::3] = bait_channel\n",
    "channels[2::3] = prey_channel\n",
    "\n",
    "def add_nested_folders(target_dirs: np.ndarray, channels: np.ndarray):\n",
    "    \n",
    "    nested_folders = []\n",
    "    for dir, channel in zip(target_dirs, channels):\n",
    "\n",
    "        channel_subdir = os.path.join(dir, channel)\n",
    "        images_subdir = os.path.join(channel_subdir, 'StitchedImages')\n",
    "        nested_folders.append(images_subdir)\n",
    "\n",
    "        if not os.path.exists(dir):\n",
    "            os.mkdir(dir)\n",
    "            os.mkdir(channel_subdir)\n",
    "            os.mkdir(images_subdir)\n",
    "\n",
    "        else:\n",
    "            print(f'ERROR: {dir} already exists!')\n",
    "\n",
    "    return nested_folders\n",
    "target_dirs = add_nested_folders(target_dirs, channels)\n",
    "for fh in file_handles:\n",
    "    print(fh)\n",
    "for index in range(len(file_handles)):\n",
    "\n",
    "    source_dir = source_dirs[index]\n",
    "    handle = file_handles[index]\n",
    "    concen = concens.index(concens[index])\n",
    "    target_dir = target_dirs[index]\n",
    "    exposure = exposures[index]\n",
    "    channel = channels[index]\n",
    "\n",
    "    target_filename = 'BGSubtracted_StitchedImg_{}_{}_{}.tif'\n",
    "    target_filename = target_filename.format(\n",
    "        exposure,\n",
    "        channel,\n",
    "        concen\n",
    "    )\n",
    "    target_filename = os.path.join(binding_path, target_dir, target_filename)\n",
    "\n",
    "    source_filename = os.path.join(\n",
    "        binding_path, \n",
    "        source_dir, \n",
    "        channel, \n",
    "        'StitchedImages',\n",
    "        'StitchedImg_{}_{}_{}.tif'.format(exposure, channel, 0)\n",
    "        )\n",
    "\n",
    "    shutil.copyfile(source_filename, target_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Establish Button Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# button_ref_image = 'path/to/button/ref/image.tif'\n",
    "# button_ref_channel, button_ref_exposure = '2', 10\n",
    "\n",
    "# button_ref = collections.ChipQuant(d3, 'button_ref')\n",
    "# button_ref.load_file(button_ref_image, button_ref_channel, button_ref_exposure)\n",
    "# button_ref.process(mapped_features = 'button')\n",
    "# button_ref.save_summary_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Bait and Prey Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process each image type as if it were a collection of kinetic images\n",
    "binding_path = '/Volumes/DuncanSSD/20231212_new_binding_code/adpr_binding/'\n",
    "bait_channel, bait_exposure = '2', '5'\n",
    "prey_channel, prey_exposure = '4', '1'\n",
    "\n",
    "# first, process the bait\n",
    "bait_handles = ['pre_wash_bait', 'post_wash_bait']\n",
    "binding_bait = collections.ButtonChamberAssaySeries(\n",
    "    device=d1,\n",
    "    descriptions=bait_handles,\n",
    "    chamber_ref=d1_ChamberRef.chip,\n",
    "    button_ref=d1_GFPQuant.chip,\n",
    "    channels=[bait_channel]\n",
    ")\n",
    "binding_bait.parse_kineticsFolders(\n",
    "    root=binding_path,\n",
    "    file_handles=bait_handles,\n",
    "    descriptors=bait_handles,\n",
    "    channel=bait_channel,\n",
    "    exposure=bait_exposure,\n",
    "    pattern=\"{}*/{}/StitchedImages\")\n",
    "binding_bait.process_kinetics(featuretype='button', low_mem=False)\n",
    "binding_bait.save_summary()\n",
    "\n",
    "# then, process the prey \n",
    "prey_handles = ['post_wash_prey']\n",
    "binding_prey = collections.ButtonChamberAssaySeries(\n",
    "    device=d1,\n",
    "    descriptions=prey_handles,\n",
    "    chamber_ref=d1_ChamberRef.chip,\n",
    "    button_ref=d1_GFPQuant.chip,\n",
    "    channels=[prey_channel]\n",
    ")\n",
    "binding_prey.parse_kineticsFolders(\n",
    "    root=binding_path,\n",
    "    file_handles=prey_handles,\n",
    "    descriptors=prey_handles,\n",
    "    channel=prey_channel,\n",
    "    exposure=prey_exposure,\n",
    "    pattern=\"{}*/{}/StitchedImages\"\n",
    ")\n",
    "binding_prey.process_kinetics(featuretype='button', low_mem=False)\n",
    "binding_prey.save_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('htbam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9d5eb981a451804117bbb533ea06cb0ae54737992d6851237fb03142364cb8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
